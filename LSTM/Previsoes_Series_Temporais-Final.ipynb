{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Previsoes-Series-Temporais.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/Alunos-UEPB-BancoDeDados/blob/master/LSTM/Previsoes_Series_Temporais-Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8xkVKhTmjKHh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# <font color='blue'>Data Science Academy - Deep Learning II</font>"
      ]
    },
    {
      "metadata": {
        "id": "CuHq7Ep_jKHi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Previsões com Séries Temporais e RNNs "
      ]
    },
    {
      "metadata": {
        "id": "DLn3I9ZAjKHl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Carregando os Dados\n",
        "\n",
        "Primeiro, devemos carregar nossas séries temporais - uma série histórica de cerca de 140 dias do preço das ações da Apple (extraído do site DataMarket - https://datamarket.com/data/list/?q=provider%3Atsdl). Em seguida, precisamos executar uma série de etapas de pré-processamento para preparar os dados para uso com um modelo RNN. \n",
        "\n",
        "É uma boa prática normalizar as séries temporais - normalizando seu range. Isso nos ajuda a evitar problemas numéricos sérios associados a funções de ativação comuns (como o tanh) que transformam números muito grandes (positivos ou negativos), além de ajudar a evitar problemas relacionados ao computar derivadas.\n",
        "\n",
        "Aqui nós normalizamos a série para ficar na faixa [0,1], mas é também é comum normalizar por um desvio padrão da série."
      ]
    },
    {
      "metadata": {
        "id": "C0uqiwiWjKHm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ec5a7d4-21dd-47c1-87e6-a65867725976"
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3jhcOmvHjKHu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "af58184b-57cb-4614-905e-77702a9c7279"
      },
      "cell_type": "code",
      "source": [
        "!mkdir datasets\n",
        "!wget \n",
        "!mv *.csv datasets\n",
        "dataset = np.loadtxt('datasets/normalized_apple_prices.csv')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3da2afd8da5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/normalized_apple_prices.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    614\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    615\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: datasets/normalized_apple_prices.csv not found."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HvcxHKzrjKHy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "plt.plot(dataset)\n",
        "plt.xlabel('Período de Tempo')\n",
        "plt.ylabel('Valores Normalizados da Série')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "scf7DbjAjKH3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Extraindo Sequências da Série Temporal"
      ]
    },
    {
      "metadata": {
        "id": "Vr0HZ0OyjKH4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lembre-se, nossa série de tempo é uma sequência de números que podemos representar em termos matemáticos, como:\n",
        "\n",
        "$$s_{0},s_{1},s_{2},...,s_{P}$$\n",
        "\n",
        "onde $ s_ {p} $ é o valor numérico das séries temporais no período de tempo $ p $ e onde $ P $ é o comprimento total da série. Para aplicar nossa RNN tratamos o problema de previsão de séries temporais como um problema de regressão e, portanto, precisamos usar uma janela deslizante para construir um conjunto de pares de entrada / saída associados para regredir. Este processo é representado no gif abaixo.\n",
        "\n",
        "<img src=\"images/timeseries_windowing_training.gif\" width=600 height=600/>\n",
        "\n",
        "Por exemplo - usando uma janela de tamanho T = 5 (como ilustrado no gif acima) produzimos um conjunto de pares de entrada / saída como o mostrado na tabela abaixo\n",
        "\n",
        "$$\n",
        "\\begin{array}{c|c}\n",
        "\\text{Input} & \\text{Output}\\\\\n",
        "\\hline \\color{CornflowerBlue} {\\langle s_{1},s_{2},s_{3},s_{4},s_{5}\\rangle} & \\color{Goldenrod}{ s_{6}} \\\\\n",
        "\\ \\color{CornflowerBlue} {\\langle s_{2},s_{3},s_{4},s_{5},s_{6} \\rangle } & \\color{Goldenrod} {s_{7} } \\\\\n",
        "\\color{CornflowerBlue}  {\\vdots} & \\color{Goldenrod} {\\vdots}\\\\\n",
        "\\color{CornflowerBlue} { \\langle s_{P-5},s_{P-4},s_{P-3},s_{P-2},s_{P-1} \\rangle } & \\color{Goldenrod} {s_{P}}\n",
        "\\end{array}$$\n",
        "\n",
        "Observe aqui que cada entrada é uma sequência (ou vetor) de comprimento 4 (e em geral tem um comprimento igual ao tamanho da janela T), enquanto cada saída correspondente é um valor escalar. Observe também como é dada uma série de tempo de comprimento P e tamanho de janela T = 5 como mostrado acima, criamos pares de entrada / saída P-5. De forma mais geral, para um tamanho de janela T, criamos P-T desses pares.\n",
        "\n",
        "Abaixo, temos uma função que cria essa janela deslizante."
      ]
    },
    {
      "metadata": {
        "id": "XezNuAuFjKH5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Função que transforma séries e window-size em um conjunto de input/output para o modelo RNN \n",
        "def window_transform_series(series, window_size):\n",
        "    \"\"\"\n",
        "      Argumentos:\n",
        "        series(np.array(list)): Sequência de valores\n",
        "        window_size(int      ): Tamanho da janela\n",
        "      \n",
        "      Retorna:\n",
        "         X(np.array(list(list))): Matriz de Input\n",
        "         y(np.array(list))      : Array de Ouput\n",
        "    \"\"\"\n",
        "\n",
        "    # Objetos para input/output \n",
        "    X = np.asarray([series[i:(i + window_size)] for i in range(len(series) - window_size)])\n",
        "    y = np.asarray([series[i + window_size] for i in range(len(series) - window_size)])\n",
        "\n",
        "    return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oLtXUWo4jKH9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aplicamos a função ao nosso conjunto de dados e definimos um windows-size = 7."
      ]
    },
    {
      "metadata": {
        "id": "3LSlCP7pjKH_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "window_size = 7\n",
        "X,y = window_transform_series(series = dataset, window_size = window_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMnf3H8ZjKIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "K8xT7XazjKIH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAuFxDt6jKIL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dados de Treino e de Teste"
      ]
    },
    {
      "metadata": {
        "id": "_7-iJoQSjKIN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para realizar testes adequados em nosso conjunto de dados, usaremos o último 1/3 dele para teste. Isto é, uma vez que treinamos nosso modelo, temos algo para testá-lo (como qualquer problema de regressão!). Esta divisão em conjuntos de treinamento/teste é feita na célula abaixo.\n",
        "\n",
        "Observe como aqui ** não ** estamos dividindo o conjunto de dados * aleatoriamente * como normalmente seria feito ao validar um modelo de regressão. Isso ocorre porque nossos pares de entrada/saída * estão relacionados temporariamente *. Não queremos validar o nosso modelo treinando em um subconjunto aleatório da série e depois testar em outro subconjunto aleatório.\n",
        "\n",
        "Queremos treinar em um pedaço sólido da série (no nosso caso, os primeiros 2/3 completos), e validar em um pedaço posterior (o último 1/3), pois isso simula como prevermos os valores do * futuro * de uma série temporal."
      ]
    },
    {
      "metadata": {
        "id": "V0mErjEfjKIO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split em treino e teste\n",
        "train_test_split = int(np.ceil(2*len(y)/float(3)))  # Ponto de spplit\n",
        "\n",
        "# Particiona os dados de treino em X e Y\n",
        "X_train = X[:train_test_split,:]\n",
        "y_train = y[:train_test_split]\n",
        "\n",
        "# Particiona os dados de teste em X e Y\n",
        "X_test = X[train_test_split:,:]\n",
        "y_test = y[train_test_split:]\n",
        "\n",
        "# Para criar o Modelo RNN LSTM com o Keras nossos dados precisam estar no formato [samples, window size, stepsize] \n",
        "X_train = np.asarray(np.reshape(X_train, (X_train.shape[0], window_size, 1)))\n",
        "X_test = np.asarray(np.reshape(X_test, (X_test.shape[0], window_size, 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0bAVlpu1jKIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BYHfCwIejKIW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ep2Z_TcHjKIb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Construindo o Modelo RNN"
      ]
    },
    {
      "metadata": {
        "id": "ce9QGAfljKId",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tendo criado pares de entrada / saída de nossas séries temporais e dividido em conjuntos de treinamento / teste, agora podemos começar a configurar nossa RNN. Usamos o Keras para criar rapidamente uma RNN de duas camadas ocultas com as  seguintes especificações\n",
        "\n",
        "- A camada 1 usa um módulo LSTM com 5 unidades escondidas (observe aqui o input_shape = (window_size, 1))\n",
        "- A camada 2 usa um módulo totalmente conectado com uma unidade\n",
        "- A perda 'mean_squared_error' deve ser usada (lembre-se: estamos realizando regressão aqui)"
      ]
    },
    {
      "metadata": {
        "id": "gknqP3hCjKIf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# RNN para regressão em nossos dados de séries temporais \n",
        "def build_RNN(window_size):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(5, input_shape=(window_size,1)))\n",
        "    model.add(Dense(1))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cIkUgS2IjKIl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cria e compila o modelo\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import keras\n",
        "\n",
        "# Random seed\n",
        "np.random.seed(0)\n",
        "\n",
        "# Build do modelo\n",
        "model = build_RNN(window_size)\n",
        "\n",
        "# Otimizador\n",
        "optimizer = keras.optimizers.RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-08, decay = 0.0)\n",
        "\n",
        "# Compila o modelo\n",
        "model.compile(loss = 'mean_squared_error', optimizer = optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xx-nvTIDjKIr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cgJXaeF7jKIy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fit do modelo"
      ]
    },
    {
      "metadata": {
        "id": "aRmRA5M8jKI0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs = 1000, batch_size = 50, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fa9ki9vojKI5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qlaXaC63jKI9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Salva o modelo\n",
        "model.save('lstm_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hHz6YBxTjKJB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Avalia a Performance do Modelo"
      ]
    },
    {
      "metadata": {
        "id": "610ydHWpjKJC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Gerando previsões\n",
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HPvzY4T3jKJG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Print dos erros de treino e de teste\n",
        "training_error = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Erro em Treinamento = %.3f %%' % training_error)\n",
        "\n",
        "testing_error = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Erro em Teste = %.3f %%' %  testing_error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BQGH7re3jKJM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Plot da série original\n",
        "plt.plot(dataset,color = 'k')\n",
        "\n",
        "# Plot das previsões em treino\n",
        "split_pt = train_test_split + window_size \n",
        "plt.plot(np.arange(window_size,split_pt,1),train_predict,color = 'b')\n",
        "\n",
        "# plot das previsões em treino\n",
        "plt.plot(np.arange(split_pt,split_pt + len(test_predict),1),test_predict,color = 'r')\n",
        "\n",
        "# Plot\n",
        "plt.xlabel('Dia')\n",
        "plt.ylabel('Preço das Ações da Apple')\n",
        "plt.legend(['Série Original','Previsões em Treino','Previsões em Teste'], loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZQdCf4HxjKJQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Previsões com Novos Conjuntos de Dados"
      ]
    },
    {
      "metadata": {
        "id": "O-VqpfsDjKJQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "No arquivo pdf onde você encontrou este Jupyter Notebook, estão descritos o procedimento para aplicar seu modelo criado a novos conjuntos de dados. Tudo que você fez no seu conjunto de dados para realizar o treinamento, deve ser repetido em um novo conjunto de dados que você queira usar para fazer as previsões. Vejamos um exemplo."
      ]
    },
    {
      "metadata": {
        "id": "Y9Cf5sz8jKJS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Carregando o modelo treinado. Repare que o nome agora é \"modelo\" e não mais \"model\". \n",
        "modelo = load_model('lstm_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "obKmrz6njKJU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Aqui está seu novo conjunto de dados. \n",
        "# Na verdade pegamos os últimos registros do dataset e queremos prever o próximo item da série.\n",
        "# Perceba que os dados já estão padronizados, pois foi assim que treinamos nosso modelo.\n",
        "new_data = [-4.362395529396456695e-02,\n",
        "            2.155369823552977238e-02,\n",
        "            2.647844739615612397e-02,\n",
        "            -4.167795105803762112e-02,\n",
        "            -7.888723449334911209e-02,\n",
        "            -5.797255139894330611e-02,\n",
        "            2.305824869067012450e-01,\n",
        "            3.360086521611651555e-01]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LtTtQ7TNjKJW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualizando os novos dados\n",
        "new_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kKG-pjcPjKJa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Agora aplicamos aos novos dados as mesms transformações aplicadas antes do processo de treinamento.\n",
        "# Criaremos o objeto new_X para diferenciar do objeto X usado no treinamento\n",
        "window_size = 7\n",
        "series = new_data\n",
        "new_X = np.asarray([series[i:(i + window_size)] for i in range(len(series) - window_size)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YZlGofLvjKJc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Shape de new_X (compare com o shape de X no início deste notebook)\n",
        "new_X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YRfQ_Y4ajKJh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(new_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q29Esr91jKJm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# O modelo LSTM espera receber os dados com 3 dimensões e por isso precisamos fazer o reshape.\n",
        "# Fizemos o mesmo durante o pré-processamento dos dados antes de criar o modelo.\n",
        "final_X = np.asarray(np.reshape(new_X, (new_X.shape[0], window_size, 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LaSboe_njKJo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Shape\n",
        "final_X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1tkpw9TijKJs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Agora fazemos as previsões com nosso modelo usando o novo conjunto de dados\n",
        "pred = modelo.predict(final_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rhfNYVFhjKJv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Próximo valor na série: \", pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9aXrnBfujKJy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fim"
      ]
    }
  ]
}