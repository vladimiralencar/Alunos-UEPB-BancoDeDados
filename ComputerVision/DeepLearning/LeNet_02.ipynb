{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet-02.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/Alunos-UEPB-BancoDeDados/blob/master/ComputerVision/DeepLearning/LeNet_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "YPNO9z-h-COD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LeNet - Rede Neural Convolucional - Classificação de Imagens - Cifar10"
      ]
    },
    {
      "metadata": {
        "id": "sTYUmKxN99FR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Leitura de dados"
      ]
    },
    {
      "metadata": {
        "id": "DH4GmQ5H8i_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "88ff78b3-6cc7-4725-d54d-01ab8dea89f5"
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/ComputerVision/DeepLearning/convnet.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-19 01:54:15--  https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/ComputerVision/DeepLearning/convnet.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6344 (6.2K) [text/plain]\n",
            "Saving to: ‘convnet.py’\n",
            "\n",
            "\rconvnet.py            0%[                    ]       0  --.-KB/s               \rconvnet.py          100%[===================>]   6.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-04-19 01:54:15 (146 MB/s) - ‘convnet.py’ saved [6344/6344]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UCAwf0EQTJ-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1023
        },
        "outputId": "3f9eb288-e99f-4687-adbd-8fceb42401b4"
      },
      "cell_type": "code",
      "source": [
        "# Rede Neural Convolucional Para Classificação de Imagens\n",
        "\n",
        "# Execute: python cap09-03-train-convnet2.py --network lenet --model output/modelo_lenet.hdf5 --epochs 20\n",
        "\n",
        "# import the necessary packages\n",
        "from convnet import ConvNetFactory\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "# hiperparametros\n",
        "network='lenet'\n",
        "model_path='modelo.hdf5'\n",
        "epochs=20\n",
        "dropout=-1\n",
        "activation=\"tanh\"\n",
        "batch_size=32\n",
        "verbose=1\n",
        "\n",
        "# Carrega os dados de treinamento e teste e, em seguida, dimensiona no intervalo [0, 1]\n",
        "print(\"\\nCarregando os dados de treino...\")\n",
        "((trainData, trainLabels), (testData, testLabels)) = cifar10.load_data()\n",
        "trainData = trainData.astype(\"float\") / 255.0\n",
        "testData = testData.astype(\"float\") / 255.0\n",
        "\n",
        "# Transforma os rótulos de treinamento e teste em vetores no intervalo [0, numClasses]\n",
        "# Isso gera um vetor para cada rótulo, onde o índice do rótulo é definido como `1` e todas as outras entradas para `0`\n",
        "# No caso do CIFAR-10, existem 10 rótulos de classe\n",
        "trainLabels = np_utils.to_categorical(trainLabels, 10)\n",
        "testLabels = np_utils.to_categorical(testLabels, 10)\n",
        "\n",
        "# Coleta os argumentos\n",
        "kargs = {\"dropout\": dropout > 0, \"activation\": activation}\n",
        "\n",
        "# Treina o modelo usando SGD\n",
        "print(\"Compilando o modelo...\")\n",
        "model = ConvNetFactory.build(network, 3, 32, 32, 10, **kargs)\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
        "\n",
        "# Inicia o treinamento\n",
        "print(\"Iniciando o treinamento...\\n\")\n",
        "model.fit(trainData, trainLabels, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
        "\n",
        "# Mostra a acurácia nos dados de teste\n",
        "(loss, accuracy) = model.evaluate(testData, testLabels, batch_size=batch_size, verbose=verbose)\n",
        "print(\"Acurácia: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Salva o modelo \n",
        "print(\"\\nSalvando o modelo...\")\n",
        "model.save(model_path)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Carregando os dados de treino...\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 19s 0us/step\n",
            "Compilando o modelo...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Iniciando o treinamento...\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 14s 272us/step - loss: 1.4209 - acc: 0.4978\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 8s 162us/step - loss: 1.1021 - acc: 0.6116\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 8s 152us/step - loss: 0.9530 - acc: 0.6677\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 8s 151us/step - loss: 0.8177 - acc: 0.7173\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 8s 151us/step - loss: 0.6788 - acc: 0.7633\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 8s 150us/step - loss: 0.5414 - acc: 0.8108\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 8s 150us/step - loss: 0.3985 - acc: 0.8618\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 7s 150us/step - loss: 0.2598 - acc: 0.9099\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 7s 150us/step - loss: 0.1525 - acc: 0.9482\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 7s 148us/step - loss: 0.0754 - acc: 0.9790\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 7s 147us/step - loss: 0.0259 - acc: 0.9953\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 8s 157us/step - loss: 0.0069 - acc: 0.9997\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 8s 157us/step - loss: 0.0031 - acc: 0.9999\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 7s 148us/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 7s 148us/step - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 7s 147us/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 7s 149us/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 7s 149us/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 7s 148us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 7s 148us/step - loss: 0.0010 - acc: 1.0000\n",
            "10000/10000 [==============================] - 1s 74us/step\n",
            "Acurácia: 70.82%\n",
            "\n",
            "Salvando o modelo...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ykott3isAwKz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Faz download do arquivo de pesos do Modelo"
      ]
    },
    {
      "metadata": {
        "id": "EH5Z9oYe_hYL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from google.colab import files \n",
        "#files.download(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}