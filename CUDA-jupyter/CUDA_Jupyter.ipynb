{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA-Jupyter.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/Alunos-UEPB-BancoDeDados/blob/master/CUDA-jupyter/CUDA_Jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uxb1Kq5YAwKZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Nvidia CUDA em GPUs - Revis√£o"
      ]
    },
    {
      "metadata": {
        "id": "rwsuiFpiAwKa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Status da GPU"
      ]
    },
    {
      "metadata": {
        "id": "gFx8c-fYAwKb",
        "colab_type": "code",
        "outputId": "7d51383f-ee3d-4898-88c9-ac72b05c7fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jan 14 15:41:09 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hNvWrpipAzJL",
        "colab_type": "code",
        "outputId": "76974e7a-b019-44e6-ef81-0bf120b3b0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 01-check-env.py\t\t  exemplo2.cu\n",
            " 02-PyCudaWorkflow.py\t\t  exemplo3.cu\n",
            " 03-PyCudaMatrixManipulation.py   exemplo4.cu\n",
            " 04-PyCudaGPUArray.py\t\t  exemplo5.cu\n",
            " 05-PyCudaElementWise.py\t  exemplo6.cu\n",
            " 06-PyCudaReductionKernel.py\t  exemplo7.cu\n",
            " cmemory\t\t\t  memory\n",
            " cmemory.cu\t\t\t  memory.cu\n",
            "'CUDA-Jupyter (1).ipynb'\t  opatomicas\n",
            " CUDA-Jupyter.ipynb\t\t 'opatomicas (1).cu'\n",
            " dotproduct\t\t\t 'opatomicas (2).cu'\n",
            "'dotproduct (1).cu'\t\t 'opatomicas (3).cu'\n",
            " dotproduct2\t\t\t  opatomicas.cu\n",
            "'dotproduct (2).cu'\t\t  pinnedmemory\n",
            "'dotproduct (3).cu'\t\t  pinnedmemory.cu\n",
            "'dotproduct (4).cu'\t\t  sample_data\n",
            " dotproduct.cu\t\t\t  smemory\n",
            " Duvida-Pycuda-01.txt\t\t  smemory.cu\n",
            " eventos\t\t\t  t2est-02-PyCudaWorkflow-test.py\n",
            " eventos.cu\t\t\t  test-02-PyCudaWorkflow-test.py\n",
            " exemplo1.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nkRzZB8kBFBU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Para importar arquivos"
      ]
    },
    {
      "metadata": {
        "id": "NnVnEKqjBESe",
        "colab_type": "code",
        "outputId": "6dd02002-b4da-4f0e-8304-0f3e535bafa0",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5f5090e6-9cd4-4a98-ac59-638c25b09a20\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5f5090e6-9cd4-4a98-ac59-638c25b09a20\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving exemplo7.cu to exemplo7 (1).cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JXtD1ck1AwKh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Paralelismo\n",
        "\n",
        "Para a primeira tarefa, vamos usar os seguintes conceitos:\n",
        "\n",
        "* <code style=\"color:green\">&#95;&#95;global&#95;&#95;</code> - Esta palavra-chave √© um qualificador usado para dizer ao compilador CUDA que a fun√ß√£o deve ser compilada para a GPU. Para o CUDA C/C ++, o compilador nvcc ir√° lidar com a compila√ß√£o deste c√≥digo.\n",
        "* <code style=\"color:green\">blockIdx.x</code> - Esta √© uma vari√°vel usada dentro de um kernel de GPU para determinar a ID do bloco que est√° atualmente executando o c√≥digo. Uma vez que haver√° muitos blocos em paralelo, precisamos desta ID para ajudar a determinar qual parte dos dados um bloco particular funcionar√°.\n",
        "* <code style=\"color:green\">threadIdx.x</code> - Esta √© uma vari√°vel usada dentro de um kernel de GPU para determinar o ID da thread que est√° atualmente executando o c√≥digo no bloco ativo.\n",
        "* <code style=\"color:green\">blockDim.x</code> - Esta √© uma vari√°vel que retorna um valor que indica o n√∫mero de threads que h√° por bloco. Lembre-se de que todos os blocos agendados para executar na GPU s√£o id√™nticos, exceto para o valor de <code style=\"color:green\">blockIdx.x</code>.\n",
        "* <code style=\"color:green\">myKernel <<< numero_de_blocos, threads_por_bloco>>> (...)</code> -  Esta √© a sintaxe usada para iniciar um kernel na GPU. Dentro de \"<<< >>>\", estabelecemos dois valores. O primeiro √© o n√∫mero total de blocos que queremos executar na GPU, e o segundo √© o n√∫mero de threads que h√° por bloco. \n",
        "\n",
        "Vamos explorar os conceitos acima, fazendo um simples exemplo de \"Hello Paralelismo\". Ao executar a c√©lula abaixo, teremos:\n",
        "\n",
        "1. A partir do arquivo de origem .cu, c√≥digo separado que deve ser compilado para a GPU e o c√≥digo que deve ser compilado para a CPU\n",
        "2. O nvcc compilar√° o pr√≥prio c√≥digo GPU\n",
        "3. nvcc dar√° ao compilador do host, no nosso caso gcc, o c√≥digo da CPU para compilar\n",
        "4. Vincula o c√≥digo compilado de # 2 e # 3 e crie o execut√°vel"
      ]
    },
    {
      "metadata": {
        "id": "9MiJ9z5bAwKi",
        "colab_type": "code",
        "outputId": "0f0c319f-8c4e-44f1-ece9-346b78a59921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "!cat exemplo1.cu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#include <stdio.h>\n",
            "\n",
            "#define NUM_BLOCKS 16\n",
            "#define BLOCK_WIDTH 1\n",
            "\n",
            "__global__ void hello()\n",
            "{\n",
            "    printf(\"Ol√°! Eu sou uma thread no bloco %d\\n\", blockIdx.x);\n",
            "}\n",
            "\n",
            "\n",
            "int main(int argc,char **argv)\n",
            "{\n",
            "    // Inicializa o kernel\n",
            "    hello<<<NUM_BLOCKS, BLOCK_WIDTH>>>();\n",
            "\n",
            "    // Sincroniza todas as threads antes de passar o controle de volta para a CPU\n",
            "    cudaDeviceSynchronize();\n",
            "\n",
            "    printf(\"Processamento Conclu√≠do!\\n\");\n",
            "\n",
            "    return 0;\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z0kod7UOAwKn",
        "colab_type": "code",
        "outputId": "6052ffb9-1e50-460a-e5ad-8ed57980a0e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "# Compila o exemplo1 e executa o programa gerado\n",
        "!nvcc -o exemplo1_out exemplo1.cu -run"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ol√°! Eu sou uma thread no bloco 5\n",
            "Ol√°! Eu sou uma thread no bloco 3\n",
            "Ol√°! Eu sou uma thread no bloco 12\n",
            "Ol√°! Eu sou uma thread no bloco 10\n",
            "Ol√°! Eu sou uma thread no bloco 13\n",
            "Ol√°! Eu sou uma thread no bloco 7\n",
            "Ol√°! Eu sou uma thread no bloco 6\n",
            "Ol√°! Eu sou uma thread no bloco 14\n",
            "Ol√°! Eu sou uma thread no bloco 8\n",
            "Ol√°! Eu sou uma thread no bloco 15\n",
            "Ol√°! Eu sou uma thread no bloco 1\n",
            "Ol√°! Eu sou uma thread no bloco 0\n",
            "Ol√°! Eu sou uma thread no bloco 11\n",
            "Ol√°! Eu sou uma thread no bloco 2\n",
            "Ol√°! Eu sou uma thread no bloco 9\n",
            "Ol√°! Eu sou uma thread no bloco 4\n",
            "Processamento Conclu√≠do!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7E8zJKfuAwKs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inicializando um kernel na GPU - Unified Memory"
      ]
    },
    {
      "metadata": {
        "id": "3MXA87cFAwKt",
        "colab_type": "code",
        "outputId": "cfb4c054-ec3a-4fcc-cda6-11cc72755da2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        }
      },
      "cell_type": "code",
      "source": [
        "!cat exemplo2.cu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#include <stdio.h>\n",
            "#include <iostream>\n",
            "\n",
            "// N√∫mero de elementos em cada vetor\n",
            "#define N 2048 * 2048 \n",
            "\n",
            "__global__ void my_kernel(int * a, int * b, int * c)\n",
            "{\n",
            "    // Determina a identifica√ß√£o de thread global exclusiva, por isso sabemos qual elemento processar\n",
            "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
            "    \n",
            "    if ( tid < N ) // Certifique-se de que n√£o inicializamos mais threads do que o necess√°rio\n",
            "        c[tid] = a[tid] + b[tid];\n",
            "}\n",
            "\n",
            "void report_gpu_mem()\n",
            "{\n",
            "    size_t free, total;\n",
            "    cudaMemGetInfo(&free, &total);\n",
            "    std::cout << \"Free = \" << free << \" Total = \" << total <<std::endl;\n",
            "}\n",
            "\n",
            "int main()\n",
            "{\n",
            "    int *a, *b, *c;\n",
            "\n",
            "    // N√∫mero total de bytes por vetor\n",
            "    int size = N * sizeof (int); \n",
            "\n",
            "    // Aloca mem√≥ria sem a necessidade de usar cudaMemcpy\n",
            "    cudaMallocManaged(&a, size);\n",
            "    cudaMallocManaged(&b, size);\n",
            "    cudaMallocManaged(&c, size);\n",
            "\n",
            "    // Inicializa mem√≥ria\n",
            "    for( int i = 0; i < N; ++i )\n",
            "    {\n",
            "        a[i] = i;\n",
            "        b[i] = i;\n",
            "        c[i] = 0;\n",
            "    }\n",
            "\n",
            "    int threads_per_block = 128;\n",
            "    int number_of_blocks = (N / threads_per_block) + 1;\n",
            "\n",
            "    my_kernel <<< number_of_blocks, threads_per_block >>> ( a, b, c );\n",
            "\n",
            "    // Espera at√© a GPU finalizar\n",
            "    cudaDeviceSynchronize(); \n",
            "\n",
            "    // Imprime os √∫ltimos 5 valores de c \n",
            "    for( int i = N-5; i < N; ++i )\n",
            "        printf(\"c[%d] = %d, \", i, c[i]);\n",
            "    printf (\"\\n\");\n",
            "\n",
            "    // Libera toda a nossa mem√≥ria alocada\n",
            "    report_gpu_mem();\n",
            "    cudaFree( a );\n",
            "    report_gpu_mem(); \n",
            "    cudaFree( b );\n",
            "    report_gpu_mem(); \n",
            "    cudaFree( c );\n",
            "    report_gpu_mem();\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-rNjLDvCAwKx",
        "colab_type": "code",
        "outputId": "022bc7dc-04ef-419f-b3ed-62f9cba9a4bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# Compila o exemplo2 e executa o programa gerado\n",
        "!nvcc  -o exemplo2_out exemplo2.cu -run"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c[4194299] = 8388598, c[4194300] = 8388600, c[4194301] = 8388602, c[4194302] = 8388604, c[4194303] = 8388606, \n",
            "Free = 11872174080 Total = 11996954624\n",
            "Free = 11888951296 Total = 11996954624\n",
            "Free = 11905728512 Total = 11996954624\n",
            "Free = 11922505728 Total = 11996954624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tijEgRuCAwK1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Acelerando Opera√ß√µes com Matrizes"
      ]
    },
    {
      "metadata": {
        "id": "fx1HcUeqAwK2",
        "colab_type": "code",
        "outputId": "226d8d5c-b1b5-43bd-9418-707af18363fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2125
        }
      },
      "cell_type": "code",
      "source": [
        "!cat exemplo3.cu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#include <stdio.h>\n",
            "#include \"cuda_runtime.h\"\n",
            "#include \"device_launch_parameters.h\"\n",
            "#include <iostream>\n",
            "#include <time.h>\n",
            "using namespace std;\n",
            "\n",
            "#define N 756\n",
            "\n",
            "// kernel\n",
            "__global__ void matrixMulGPU( int * a, int * b, int * c )\n",
            "{\n",
            "    int val = 0;\n",
            "\n",
            "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
            "    int col = blockIdx.y * blockDim.y + threadIdx.y;\n",
            "\n",
            "    if (row < N && col < N)\n",
            "    {\n",
            "        for ( int k = 0; k < N; ++k )\n",
            "            val += a[row * N + k] * b[k * N + col];\n",
            "        c[row * N + col] = val;\n",
            "    }\n",
            "}\n",
            "\n",
            "void matrixMulCPU( int * a, int * b, int * c )\n",
            "{\n",
            "    int val = 0;\n",
            "\n",
            "    for( int row = 0; row < N; ++row )\n",
            "        for( int col = 0; col < N; ++col )\n",
            "        {\n",
            "            val = 0;\n",
            "            for ( int k = 0; k < N; ++k )\n",
            "                val += a[row * N + k] * b[k * N + col];\n",
            "            c[row * N + col] = val;\n",
            "        }\n",
            "}\n",
            "\n",
            "int main()\n",
            "{\n",
            "    int *a, *b, *c_cpu, *c_gpu;\n",
            "\n",
            "    // N√∫mero de bytes de uma matriz N x N \n",
            "    int size = N * N * sizeof (int); \n",
            "\n",
            "    // Aloca mem√≥ria\n",
            "    cudaMallocManaged (&a, size);\n",
            "    cudaMallocManaged (&b, size);\n",
            "    cudaMallocManaged (&c_cpu, size);\n",
            "    cudaMallocManaged (&c_gpu, size);\n",
            "\n",
            "    // Inicializa mem√≥ria\n",
            "    for( int row = 0; row < N; ++row )\n",
            "        for( int col = 0; col < N; ++col )\n",
            "        {\n",
            "            a[row * N + col] = row;\n",
            "            b[row * N + col] = col+2;\n",
            "            c_cpu[row * N + col] = 0;\n",
            "            c_gpu[row * N + col] = 0;\n",
            "        }\n",
            "\n",
            "    // Bloco de threads 16 x 16     \n",
            "    dim3 threads_per_block (16, 16, 1); \n",
            "    dim3 number_of_blocks ((N / threads_per_block.x) + 1, (N / threads_per_block.y) + 1, 1);\n",
            "\n",
            "    // Define 2 eventos CUDA\n",
            "    cudaEvent_t start, end;\n",
            "\n",
            "    // Cria os eventos\n",
            "    cudaEventCreate(&start);\n",
            "    cudaEventCreate(&end);\n",
            "\n",
            "    // Registra o primeiro evento\n",
            "    cudaEventRecord(start);\n",
            "\n",
            "    // Chamada ao kernel\n",
            "    matrixMulGPU <<< number_of_blocks, threads_per_block >>> ( a, b, c_gpu );\n",
            "\n",
            "    // Registra o segundo evento\n",
            "    cudaEventRecord(end);\n",
            "\n",
            "    // Aguarda a GPU finalizar seu trabalho\n",
            "    cudaDeviceSynchronize(); \n",
            "\n",
            "    // Calcula o tempo usado no processamento\n",
            "    float elapsed;\n",
            "    cudaEventElapsedTime(&elapsed, start, end);\n",
            "\n",
            "    cout << \"Tempo de processamento na GPU igual a \" << elapsed << \" msec (aproximadamente 0.01108 segundos)\" << endl;\n",
            "\n",
            "    clock_t start1, end1;\n",
            "    double cpu_time_used;\n",
            "\n",
            "    start1 = clock();\n",
            "\n",
            "    // Chama a vers√£o para CPU para checar nosso trabalho\n",
            "    matrixMulCPU( a, b, c_cpu );\n",
            "\n",
            "    // Calcula o tempo usado no processamento\n",
            "    end1 = clock();\n",
            "    cpu_time_used = ((double) (end1 - start1)) / CLOCKS_PER_SEC;\n",
            "\n",
            "    cout << \"Tempo de processamento na CPU igual a \" << cpu_time_used << \" sec\" << endl;\n",
            "\n",
            "    // Compara as duas respostas para garantir que elas sejam iguais\n",
            "    bool error = false;\n",
            "    for( int row = 0; row < N && !error; ++row )\n",
            "        for( int col = 0; col < N && !error; ++col )\n",
            "            if (c_cpu[row * N + col] != c_gpu[row * N + col])\n",
            "            {\n",
            "                printf(\"FOUND ERROR at c[%d][%d]\\n\", row, col);\n",
            "                error = true;\n",
            "                break;\n",
            "            }\n",
            "    if (!error)\n",
            "        printf(\"Successo! As duas matrizes s√£o iguais, sendo executadas na CPU e na GPU!\\n\");\n",
            "\n",
            "    // Libera a mem√≥ria\n",
            "    cudaFree(a); \n",
            "    cudaFree(b);\n",
            "    cudaFree( c_cpu ); \n",
            "    cudaFree( c_gpu );\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dsEQ_ILeAwK8",
        "colab_type": "code",
        "outputId": "76607753-7e98-4a76-e119-a44f8bebf011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Compila o exemplo3 e executa o programa gerado\n",
        "!nvcc  -o exemplo3_out exemplo3.cu -run"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tempo de processamento na GPU igual a 68.1403 msec (aproximadamente 0.01108 segundos)\n",
            "Tempo de processamento na CPU igual a 1.89718 sec\n",
            "Successo! As duas matrizes s√£o iguais, sendo executadas na CPU e na GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tfdW4rFbJToX",
        "colab_type": "code",
        "outputId": "7acf25c9-3489-4e16-fdd6-3eec742ed6b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!ls sample_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anscombe.json\t\t      mnist_test.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sc2tbSE5AwLB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tratamento de Erro\n",
        "\n",
        "Se voc√™ alterar consideravelmente o n√∫mero de blocos e threads por bloco nos exemplos acima, voc√™ pode notar alguns casos em que voc√™ n√£o receba a resposta esperada. At√© este ponto, n√£o adicionamos nenhum tipo de verifica√ß√£o de erros, o que torna muito dif√≠cil dizer por que um problema est√° ocorrendo. A verifica√ß√£o de erros √© t√£o importante quando a programa√ß√£o para um GPU quanto para uma CPU. Ent√£o vamos adicionar uma verifica√ß√£o de erro e ver se podemos introduzir alguns erros para capturar.\n",
        "\n",
        "**Nota**: √â altamente encorajado que voc√™ inclua verifica√ß√£o de erros em seu c√≥digo sempre que poss√≠vel!"
      ]
    },
    {
      "metadata": {
        "id": "haDx2vsFAwLC",
        "colab_type": "code",
        "outputId": "c444ebc1-9851-4a91-9831-dee69a981cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "cell_type": "code",
      "source": [
        "!cat exemplo4.cu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#include <stdio.h>\n",
            "\n",
            "// N√∫mero de elementos em cada vetor\n",
            "#define N 2048 * 2048\n",
            "\n",
            "__global__ void my_kernel(float scalar, float * x, float * y)\n",
            "{\n",
            "    // Determina a identifica√ß√£o de thread global exclusiva, por isso sabemos qual elemento processar\n",
            "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
            "    \n",
            "    // Certifique-se de que ainda temos threads dispon√≠veis!\n",
            "    if ( tid < N ) \n",
            "        y[tid] = scalar * x[tid] + y[tid];\n",
            "}\n",
            "\n",
            "int main()\n",
            "{\n",
            "    float *x, *y;\n",
            "\n",
            "    // O n√∫mero total de bytes por vetor\n",
            "    int size = N * sizeof (float); \n",
            "\n",
            "    cudaError_t ierrAsync;\n",
            "    cudaError_t ierrSync;\n",
            "\n",
            "    // Aloca mem√≥ria\n",
            "    cudaMallocManaged(&x, size);\n",
            "    cudaMallocManaged(&y, size);\n",
            "\n",
            "    // Inicializa a mem√≥ria\n",
            "    for( int i = 0; i < N; ++i )\n",
            "    {\n",
            "        x[i] = 1.0f;\n",
            "        y[i] = 2.0f;\n",
            "    }\n",
            "\n",
            "    int threads_per_block = 256;\n",
            "    int number_of_blocks = (N / threads_per_block) + 1;\n",
            "\n",
            "    my_kernel <<< number_of_blocks, threads_per_block >>> ( 2.0f, x, y );\n",
            "\n",
            "    ierrSync = cudaGetLastError();\n",
            "\n",
            "    // Aguarde at√© que a GPU termine\n",
            "    ierrAsync = cudaDeviceSynchronize(); \n",
            "\n",
            "    // Verifica status de execu√ß√£o\n",
            "    if (ierrSync != cudaSuccess) { printf(\"Sync error: %s\\n\", cudaGetErrorString(ierrSync)); }\n",
            "    if (ierrAsync != cudaSuccess) { printf(\"Async error: %s\\n\", cudaGetErrorString(ierrAsync)); }\n",
            "\n",
            "    // Imprime o erro m√°ximo\n",
            "    float maxError = 0;\n",
            "    for( int i = 0; i < N; ++i )\n",
            "        if (abs(4-y[i]) > maxError) { maxError = abs(4-y[i]); }\n",
            "    printf(\"Max Error: %.5f\", maxError);\n",
            "\n",
            "    // Libera a mem√≥ria alocada\n",
            "    cudaFree( x ); cudaFree( y );\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DnmnvQIyAwLG",
        "colab_type": "code",
        "outputId": "7c287808-7d39-42de-ded6-efc30713639e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Compila o exemplo4 e executa o programa gerado\n",
        "!nvcc  -o exemplo4_out exemplo4.cu -run"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Error: 0.00000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xFbOrPE-AwLJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Consultado os Par√¢metros da GPU\n",
        "\n",
        "A API de gerenciamento de dispositivos CUDA C / C ++ permite que um programador consulte o n√∫mero de dispositivos dispon√≠veis em um sistema e os recursos de cada dispositivo. O c√≥digo simples abaixo ilustra o uso da API de gerenciamento de dispositivos. Depois que o n√∫mero de dispositivos habilitados para CUDA conectados ao sistema √© determinado via `cudaGetDeviceCount()`, um loop sobre esses dispositivos √© realizado (observe que os dispositivos s√£o enumerados a partir de 0) e a fun√ß√£o `cudaGetDeviceProperties()` √© usada para retornar informa√ß√µes sobre um dispositivo em uma vari√°vel de tipo `cudaDeviceProp`. "
      ]
    },
    {
      "metadata": {
        "id": "LeVIggyWAwLK",
        "colab_type": "code",
        "outputId": "1e9d90b4-c676-40a9-98df-44108bb6d619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1343
        }
      },
      "cell_type": "code",
      "source": [
        "!cat exemplo5.cu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#include <stdio.h>\n",
            "\n",
            "#define NX 200\n",
            "#define NY 100\n",
            "\n",
            "__global__ void my_kernel2D(float scalar, float * x, float * y)\n",
            "{\n",
            "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
            "    int col = blockIdx.y * blockDim.y + threadIdx.y;\n",
            "    \n",
            "    // Verifica se ainda temos threads antes de executar a opera√ß√£o\n",
            "    if ( row < NX && col < NY ) \n",
            "        y[row * NY + col] = scalar * x[row * NY + col] + y[row * NY + col];\n",
            "}\n",
            "\n",
            "int main()\n",
            "{\n",
            "    float *x, *y;\n",
            "    float maxError = 0;\n",
            "\n",
            "    // Total de bytes por vetor\n",
            "    int size = NX * NY * sizeof (float); \n",
            "\n",
            "    cudaError_t ierrAsync;\n",
            "    cudaError_t ierrSync;\n",
            "\n",
            "    cudaDeviceProp prop;\n",
            "\n",
            "    // Aloca mem√≥ria\n",
            "    cudaMallocManaged(&x, size);\n",
            "    cudaMallocManaged(&y, size);\n",
            "\n",
            "    // Inicializa mem√≥ria\n",
            "    for( int i = 0; i < NX*NY; ++i )\n",
            "    {\n",
            "        x[i] = 1.0f;\n",
            "        y[i] = 2.0f;\n",
            "    }\n",
            "\n",
            "    dim3 threads_per_block (32,16,1);\n",
            "    dim3 number_of_blocks ((NX/threads_per_block.x)+1, (NY/threads_per_block.y)+1, 1);\n",
            "\n",
            "    cudaGetDeviceProperties(&prop, 0);\n",
            "    if (threads_per_block.x * threads_per_block.y * threads_per_block.z > prop.maxThreadsPerBlock) {\n",
            "        printf(\"Muitas threads por bloco ... finalizando\\n\");\n",
            "        goto cleanup;\n",
            "    }\n",
            "    if (threads_per_block.x > prop.maxThreadsDim[0]) {\n",
            "        printf(\"Muitas threads na dimens√£o x ... finalizando\\n\");\n",
            "        goto cleanup;\n",
            "    }\n",
            "    if (threads_per_block.y > prop.maxThreadsDim[1]) {\n",
            "        printf(\"Muitas threads na dimens√£o y ... finalizando\\n\");\n",
            "        goto cleanup;\n",
            "    }\n",
            "    if (threads_per_block.z > prop.maxThreadsDim[2]) {\n",
            "        printf(\"Muitas threads na dimens√£o z ... finalizando\\n\");\n",
            "        goto cleanup;\n",
            "    }\n",
            "\n",
            "    my_kernel2D <<< number_of_blocks, threads_per_block >>> ( 2.0f, x, y );\n",
            "\n",
            "    ierrSync = cudaGetLastError();\n",
            "\n",
            "    // Espera a GPU finalizar\n",
            "    ierrAsync = cudaDeviceSynchronize(); \n",
            "    if (ierrSync != cudaSuccess) { printf(\"Sync error: %s\\n\", cudaGetErrorString(ierrSync)); }\n",
            "    if (ierrAsync != cudaSuccess) { printf(\"Async error: %s\\n\", cudaGetErrorString(ierrAsync)); }\n",
            "\n",
            "    // Imprime o erro\n",
            "    for( int i = 0; i < NX*NY; ++i )\n",
            "        if (abs(4-y[i]) > maxError) { maxError = abs(4-y[i]); }\n",
            "    printf(\"Max Error: %.5f\", maxError);\n",
            "\n",
            "cleanup:\n",
            "    // Libera mem√≥ria alocada\n",
            "    cudaFree( x ); cudaFree( y );\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "of2unynTAwLN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tente digitar tamanhos diferentes na linha de dimens√£o do bloco, `dim3 threads_per_block (32,16,1);` e verifique se o seu novo controle de propriedade do dispositivo GPU funciona corretamente!\n",
        "\n",
        "√Ä medida que voc√™ come√ßa a escrever c√≥digo de GPU que possivelmente poderia executar em m√∫ltiplos ou diferentes tipos de GPUs, voc√™ deve usar a capacidade de consultar facilmente cada dispositivo para determinar a configura√ß√£o ideal para seu c√≥digo."
      ]
    },
    {
      "metadata": {
        "id": "uwAdlFuvAwLP",
        "colab_type": "code",
        "outputId": "d95e0e71-1fd2-4a15-b305-25cc126f3106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Compila o exemplo5 e executa o programa gerado\n",
        "!nvcc  -o exemplo5_out exemplo5.cu -run"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Error: 0.00000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "btkype-tAwLV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Gerenciamento de Mem√≥ria\n",
        "\n",
        "√â importante perceber que a GPU tem sua pr√≥pria mem√≥ria f√≠sica; Assim como a CPU usa a RAM do sistema para sua mem√≥ria. Ao executar o c√≥digo na GPU, temos de garantir que todos os dados necess√°rios sejam copiados primeiro no barramento PCI-Express para a mem√≥ria da GPU antes de iniciar nossos kernels.\n",
        "\n",
        "* `cudaMalloc ( void** devPtr, size_t size )` - Esta chamada de API √© usada para alocar mem√≥ria na GPU, e √© muito semelhante ao uso de `malloc` na CPU. Voc√™ fornece o endere√ßo de um ponteiro que apontar√° para a mem√≥ria ap√≥s a conclus√£o da chamada, assim como o n√∫mero de bytes a serem alocados.\n",
        "\n",
        "* `cudaMemcpy ( void* dst, const void* src, size_t count, cudaMemcpyKind kind )` - Tamb√©m √© muito semelhante ao padr√£o `memcpy`, esta chamada API √© usada para copiar dados entre a CPU e o GPU. √â preciso um ponteiro de destino, um ponteiro de origem, o n√∫mero de bytes a copiar e o quarto par√¢metro indica qual dire√ß√£o os dados est√£o viajando: GPU-> CPU, CPU-> GPU ou GPU-> GPU.\n",
        "\n",
        "* `cudaFree ( void* devPtr )` - Usamos essa chamada de API para liberar qualquer mem√≥ria que alocamos no GPU.\n",
        "\n",
        "* `cudaMallocManaged ( T** devPtr, size_t size );` - aloca `size` bytes na mem√≥ria gerenciada e armazena em devPtr.\n",
        "\n",
        "* `cudaFree ( void* devPtr )` - Usamos essa chamada de API para liberar qualquer mem√≥ria que alocamos na mem√≥ria gerenciada.\n",
        "\n",
        "Depois de ter usado `cudaMallocManaged` para alocar alguns dados, voc√™ apenas usa o ponteiro em seu c√≥digo, independentemente de ser a CPU ou a GPU acessando os dados. Antes da Mem√≥ria Unificada, normalmente voc√™ tinha dois indicadores associados aos dados; Um para a mem√≥ria da CPU e um para a mem√≥ria do GPU (geralmente usando o nome da GPU precedido com um `d_` para indicar a mem√≥ria do dispositivo).\n",
        "\n",
        "A mem√≥ria gerenciada √© sincronizada entre os espa√ßos de mem√≥ria no lan√ßamento do kernel e quaisquer pontos de sincroniza√ß√£o do dispositivo. Isso significa que, nas arquiteturas Kepler e Maxwell, um ponto de sincroniza√ß√£o expl√≠cito (normalmente `cudaDeviceSynchronize ()`) precisa ser inserido ap√≥s um lan√ßamento do kernel, mas antes que o host use dados gerados por esse kernel. Visite a documenta√ß√£o CUDA [page on Unified Memory](http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-unified-memory-programming-hd) para mais detalhes sobre mem√≥ria unificada."
      ]
    },
    {
      "metadata": {
        "id": "w7Qfu6U6AwLW",
        "colab_type": "code",
        "outputId": "991970f0-4fce-44ff-9dd2-6988840eb9d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "cell_type": "code",
      "source": [
        "!cat exemplo6.cu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#include <string.h>\n",
            "#include <stdio.h>\n",
            "\n",
            "struct DataElement\n",
            "{\n",
            "  char *name;\n",
            "  int value;\n",
            "};\n",
            "\n",
            "__global__ void Kernel(DataElement *elem) {\n",
            "  printf(\"On device: name=%s, value=%d\\n\", elem->name, elem->value);\n",
            "\n",
            "  elem -> name[0] = 'd';\n",
            "  elem -> value++;\n",
            "}\n",
            "\n",
            "void launch(DataElement *elem) {\n",
            "  Kernel <<< 1, 1 >>> (elem);\n",
            "  cudaDeviceSynchronize();\n",
            "}\n",
            "\n",
            "int main(void)\n",
            "{\n",
            "  DataElement *e;\n",
            "  cudaMallocManaged((void**)&e, sizeof(DataElement));\n",
            "\n",
            "  e->value = 10;\n",
            "  cudaMallocManaged((void**)&(e->name), sizeof(char) * (strlen(\"hello\") + 1) );\n",
            "  strcpy(e->name, \"hello\");\n",
            "\n",
            "  launch(e);\n",
            "\n",
            "  printf(\"On host: name=%s, value=%d\\n\", e->name, e->value);\n",
            "\n",
            "  cudaFree(e->name);\n",
            "  cudaFree(e);\n",
            "\n",
            "  cudaDeviceReset();\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IydSUh1zAwLb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Voc√™ pode ver por que a mem√≥ria unificada √© atraente - ela remove o requisito de c√≥digo de gerenciamento de dados complexo. Permitindo que voc√™ obtenha suas fun√ß√µes executando na GPU com menos esfor√ßo de desenvolvimento."
      ]
    },
    {
      "metadata": {
        "id": "Q38PXLS4AwLd",
        "colab_type": "code",
        "outputId": "3d7d5f3a-07be-411f-f0ff-e73708715f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Compila o exemplo6 e executa o programa gerado\n",
        "!nvcc -o exemplo6_out exemplo6.cu -run"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On device: name=hello, value=10\n",
            "On host: name=dello, value=11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QMhPSKHtAwLk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Transposta da Matriz"
      ]
    },
    {
      "metadata": {
        "id": "efRY8dvaAwLl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Neste exemplo vamos programar um algoritmo para [Transposta da Matriz](http://en.wikipedia.org/wiki/Transpose).  Por motivos de simplicidade, usaremos matrizes quadradas. Isso nos permitir√° focar as importantes t√©cnicas de otimiza√ß√£o de mem√≥ria sem se preocupar com matrizes de forma desigual. \n",
        "\n",
        "O algoritmo de transposi√ß√£o da matriz √© definido como $A_{i,j} = B_{j,i}$ onde $A$ e $B$ s√£o $M \\times M$ matrizes e os √≠ndices $i,j$ s√£o os √≠ndices de linha e coluna, respectivamente.  (Nos exerc√≠cios de hoje vamos usar [column-major](http://en.wikipedia.org/wiki/Row-major_order#Column-major_order) para ordena√ß√£o dos elementos.)\n",
        "\n",
        "Por exemplo, se voc√™ tem um $3 \\times 3$ matriz $A$ como a seguinte $$A = \\left( \\begin{array}{ccc}\n",
        "a & d & g \\\\\n",
        "b & e & h \\\\\n",
        "c & f & i \\end{array} \\right),$$\n",
        "ent√£o a transposta da matriz dado por $A^{T}$ √©\n",
        "$$A^{T} = \\left( \\begin{array}{ccc}\n",
        "a & b & c \\\\\n",
        "d & e & f \\\\\n",
        "g & h & i \\end{array} \\right).$$\n",
        "\n",
        "Este exemplo consiste em tr√™s tarefas. "
      ]
    },
    {
      "metadata": {
        "id": "Hr7WzK3CAwLn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Error Checking\n",
        "\n",
        "Uma das t√©cnicas de programa√ß√£o mais importantes para escrever c√≥digo robusto √© fazer uma verifica√ß√£o de erros adequada. Todas as fun√ß√µes de tempo de execu√ß√£o em CUDA retornam um c√≥digo de erro do tipo ** `cudaError_t` **. √â uma boa pr√°tica verificar o c√≥digo de erro retornado de todas as fun√ß√µes CUDA. Neste exemplo 7, fornecemos duas macros para ajud√°-lo a fazer isso. Primeiro, voc√™ pode usar `CUDA_CALL (F)` para envolver cada chamada que voc√™ faz na API de tempo de execu√ß√£o do CUDA. Por exemplo, em vez de escrever\n",
        "\n",
        "```cpp\n",
        "cudaMemcpy( h_c, c, sizeof(float), cudaMemcpyHostToDevice );\n",
        "```\n",
        "\n",
        "voc√™ poderia escrever\n",
        "\n",
        "```cpp\n",
        "CUDA_CALL( cudaMemcpy( h_c, c, sizeof(float), cudaMemcpyHostToDevice ) );\n",
        "```\n",
        "\n",
        "e isso ir√° verificar o c√≥digo de retorno do `cudaMemcpy` e inform√°-lo se houver um erro.\n",
        "\n",
        "Existe uma exce√ß√£o para esse uso e √© quando se chama kernels. Kernels n√£o retornam nenhum valor. Para verificar se um kernel foi iniciado corretamente, voc√™ pode fazer o seguinte. Se voc√™ tiver um lan√ßamento do kernel\n",
        "\n",
        "```cpp\n",
        "kernel<<< 256, 256 >>>( d_a, d_b, d_c );\n",
        "```\n",
        "\n",
        "voc√™ usaria a macro `CUDA_CHECK()` seguida por `CUDA_CALL( cudaDeviceSynchronize )` conforme abaixo\n",
        "\n",
        "```cpp\n",
        "kernel<<< 256, 256 >>>( d_a, d_b, d_c );\n",
        "CUDA_CHECK()\n",
        "CUDA_CALL( cudaDeviceSynchronize() );`\n",
        "```\n",
        "\n",
        "Nas macros de verifica√ß√£o de erros que fornecemos, se houver um erro, voc√™ receber√° uma mensagem impressa na tela e o programa terminar√°. Se nenhum erro for detectado, o programa executar√° normalmente."
      ]
    },
    {
      "metadata": {
        "id": "9asnowATAwLo",
        "colab_type": "code",
        "outputId": "eb1e648e-65af-49db-e877-ad0fc397b722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3723
        }
      },
      "cell_type": "code",
      "source": [
        "!cat exemplo7.cu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/*\n",
            " *  Copyright 2014 NVIDIA Corporation\n",
            " *\n",
            " *  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            " *  you may not use this file except in compliance with the License.\n",
            " *  You may obtain a copy of the License at\n",
            " *\n",
            " *      http://www.apache.org/licenses/LICENSE-2.0\n",
            " *\n",
            " *  Unless required by applicable law or agreed to in writing, software\n",
            " *  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            " *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            " *  See the License for the specific language governing permissions and\n",
            " *  limitations under the License.\n",
            " */\n",
            "\n",
            "#include <stdio.h>\n",
            "\n",
            "#ifdef DEBUG\n",
            "#define CUDA_CALL(F)  if( (F) != cudaSuccess ) \\\n",
            "  {printf(\"Error %s at %s:%d\\n\", cudaGetErrorString(cudaGetLastError()), \\\n",
            "   __FILE__,__LINE__); exit(-1);} \n",
            "#define CUDA_CHECK()  if( (cudaPeekAtLastError()) != cudaSuccess ) \\\n",
            "  {printf(\"Error %s at %s:%d\\n\", cudaGetErrorString(cudaGetLastError()), \\\n",
            "   __FILE__,__LINE__-1); exit(-1);} \n",
            "#else\n",
            "#define CUDA_CALL(F) (F)\n",
            "#define CUDA_CHECK() \n",
            "#endif\n",
            "\n",
            "/* definitions of threadblock size in X and Y directions */\n",
            "\n",
            "#define THREADS_PER_BLOCK_X 32\n",
            "#define THREADS_PER_BLOCK_Y 32\n",
            "\n",
            "/* definition of matrix linear dimension */\n",
            "\n",
            "#define SIZE 4096\n",
            "\n",
            "/* macro to index a 1D memory array with 2D indices in column-major order */\n",
            "\n",
            "#define INDX( row, col, ld ) ( ( (col) * (ld) ) + (row) )\n",
            "\n",
            "/* CUDA kernel for naive matrix transpose */\n",
            "\n",
            "__global__ void naive_cuda_transpose( const int m, \n",
            "                                      const double * const a, \n",
            "                                      double * const c )\n",
            "{\n",
            "  const int myRow = blockDim.x * blockIdx.x + threadIdx.x;\n",
            "  const int myCol = blockDim.y * blockIdx.y + threadIdx.y;\n",
            "\n",
            "  if( myRow < m && myCol < m )\n",
            "  {\n",
            "    c[INDX( myRow, myCol, m )] = a[INDX( myCol, myRow, m )];\n",
            "  } /* end if */\n",
            "  return;\n",
            "\n",
            "} /* end naive_cuda_transpose */\n",
            "\n",
            "void host_transpose( const int m, const double * const a, double *c )\n",
            "{\n",
            "\t\n",
            "/* \n",
            " *  naive matrix transpose goes here.\n",
            " */\n",
            " \n",
            "  for( int j = 0; j < m; j++ )\n",
            "  {\n",
            "    for( int i = 0; i < m; i++ )\n",
            "      {\n",
            "        c[INDX(i,j,m)] = a[INDX(j,i,m)];\n",
            "      } /* end for i */\n",
            "  } /* end for j */\n",
            "\n",
            "} /* end host_dgemm */\n",
            "\n",
            "int main( int argc, char *argv[] )\n",
            "{\n",
            "\n",
            "  int size = SIZE;\n",
            "\n",
            "  fprintf(stdout, \"Matrix size is %d\\n\",size);\n",
            "\n",
            "/* declaring pointers for array */\n",
            "\n",
            "  double *h_a, *h_c;\n",
            "  double *d_a, *d_c;\n",
            " \n",
            "  size_t numbytes = (size_t) size * (size_t) size * sizeof( double );\n",
            "\n",
            "/* allocating host memory */\n",
            "\n",
            "  h_a = (double *) malloc( numbytes );\n",
            "  if( h_a == NULL )\n",
            "  {\n",
            "    fprintf(stderr,\"Error in host malloc h_a\\n\");\n",
            "    return 911;\n",
            "  }\n",
            "\n",
            "  h_c = (double *) malloc( numbytes );\n",
            "  if( h_c == NULL )\n",
            "  {\n",
            "    fprintf(stderr,\"Error in host malloc h_c\\n\");\n",
            "    return 911;\n",
            "  }\n",
            "\n",
            "/* allocating device memory */\n",
            "\n",
            "  CUDA_CALL( cudaMalloc( (void**) &d_a, numbytes ) );\n",
            "  CUDA_CALL( cudaMalloc( (void**) &d_c, numbytes ) );\n",
            "\n",
            "/* set result matrices to zero */\n",
            "\n",
            "  memset( h_c, 0, numbytes );\n",
            "  CUDA_CALL( cudaMemset( d_c, 0, numbytes ) );\n",
            "\n",
            "  fprintf( stdout, \"Total memory required per matrix is %lf MB\\n\", \n",
            "     (double) numbytes / 1000000.0 );\n",
            "\n",
            "/* initialize input matrix with random value */\n",
            "\n",
            "  for( int i = 0; i < size * size; i++ )\n",
            "  {\n",
            "    h_a[i] = double( rand() ) / ( double(RAND_MAX) + 1.0 );\n",
            "  }\n",
            "\n",
            "/* copy input matrix from host to device */\n",
            "\n",
            "  CUDA_CALL( cudaMemcpy( d_a, h_a, numbytes, cudaMemcpyHostToDevice ) );\n",
            "\n",
            "/* create and start timer */\n",
            "\n",
            "  cudaEvent_t start, stop;\n",
            "  CUDA_CALL( cudaEventCreate( &start ) );\n",
            "  CUDA_CALL( cudaEventCreate( &stop ) );\n",
            "  CUDA_CALL( cudaEventRecord( start, 0 ) );\n",
            "\n",
            "/* call naive cpu transpose function */\n",
            "\n",
            "  host_transpose( size, h_a, h_c );\n",
            "\n",
            "/* stop CPU timer */\n",
            "\n",
            "  CUDA_CALL( cudaEventRecord( stop, 0 ) );\n",
            "  CUDA_CALL( cudaEventSynchronize( stop ) );\n",
            "  float elapsedTime;\n",
            "  CUDA_CALL( cudaEventElapsedTime( &elapsedTime, start, stop ) );\n",
            "\n",
            "/* print CPU timing information */\n",
            "\n",
            "  fprintf(stdout, \"Total time CPU is %f sec\\n\", elapsedTime / 1000.0f );\n",
            "  fprintf(stdout, \"Performance is %f GB/s\\n\", \n",
            "    8.0 * 2.0 * (double) size * (double) size / \n",
            "    ( (double) elapsedTime / 1000.0 ) * 1.e-9 );\n",
            "\n",
            "/* setup threadblock size and grid sizes */\n",
            "\n",
            "  dim3 threads( THREADS_PER_BLOCK_X, THREADS_PER_BLOCK_Y, 1 );\n",
            "  dim3 blocks( ( size / THREADS_PER_BLOCK_X ) + 1, \n",
            "               ( size / THREADS_PER_BLOCK_Y ) + 1, 1 );\n",
            "\n",
            "/* start timers */\n",
            "  CUDA_CALL( cudaEventRecord( start, 0 ) );\n",
            "\n",
            "/* call naive GPU transpose kernel */\n",
            "\n",
            "  naive_cuda_transpose<<< blocks, threads >>>( size, d_a, d_c );\n",
            "  CUDA_CHECK()\n",
            "  CUDA_CALL( cudaDeviceSynchronize() );\n",
            "\n",
            "/* stop the timers */\n",
            "\n",
            "  CUDA_CALL( cudaEventRecord( stop, 0 ) );\n",
            "  CUDA_CALL( cudaEventSynchronize( stop ) );\n",
            "  CUDA_CALL( cudaEventElapsedTime( &elapsedTime, start, stop ) );\n",
            "\n",
            "/* print GPU timing information */\n",
            "\n",
            "  fprintf(stdout, \"Total time GPU is %f sec\\n\", elapsedTime / 1000.0f );\n",
            "  fprintf(stdout, \"Performance is %f GB/s\\n\", \n",
            "    8.0 * 2.0 * (double) size * (double) size / \n",
            "    ( (double) elapsedTime / 1000.0 ) * 1.e-9 );\n",
            "\n",
            "/* copy data from device to host */\n",
            "\n",
            "  CUDA_CALL( cudaMemset( d_a, 0, numbytes ) );\n",
            "  CUDA_CALL( cudaMemcpy( h_a, d_c, numbytes, cudaMemcpyDeviceToHost ) );\n",
            "\n",
            "/* compare GPU to CPU for correctness */\n",
            "\n",
            "  for( int j = 0; j < size; j++ )\n",
            "  {\n",
            "    for( int i = 0; i < size; i++ )\n",
            "    {\n",
            "      if( h_c[INDX(i,j,size)] != h_a[INDX(i,j,size)] ) \n",
            "      {\n",
            "        printf(\"Error in element %d,%d\\n\", i,j );\n",
            "        printf(\"Host %f, device %f\\n\",h_c[INDX(i,j,size)],\n",
            "                                      h_a[INDX(i,j,size)]);\n",
            "        printf(\"FAIL\\n\");\n",
            "        goto end;\n",
            "      } /* end fi */\n",
            "    } /* end for i */\n",
            "  } /* end for j */\n",
            "\n",
            "/* free the memory */\n",
            "  printf(\"PASS\\n\");\n",
            "\n",
            "  end:\n",
            "  free( h_a );\n",
            "  free( h_c );\n",
            "  CUDA_CALL( cudaFree( d_a ) );\n",
            "  CUDA_CALL( cudaFree( d_c ) );\n",
            "  CUDA_CALL( cudaDeviceReset() );\n",
            "\n",
            "  return 0;\n",
            "} /* end main */\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5jmog9zCAwLs",
        "colab_type": "code",
        "outputId": "edcbded0-02da-467d-a81f-b3c628b17556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Compila o exemplo7\n",
        "!nvcc -lineinfo -DDEBUG -arch=sm_30 -o exemplo7_out exemplo7.cu && echo Compilado com Sucesso!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compilado com Sucesso!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NDBFJi93AwLv",
        "colab_type": "code",
        "outputId": "156fc5e1-c365-4de4-f838-e246f5c58a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "# Executa o exemplo7\n",
        "!./exemplo7_out"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matrix size is 4096\n",
            "Total memory required per matrix is 134.217728 MB\n",
            "Total time CPU is 0.372804 sec\n",
            "Performance is 0.720043 GB/s\n",
            "Total time GPU is 0.005972 sec\n",
            "Performance is 44.952137 GB/s\n",
            "PASS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iV4tBR2IAwL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se quiser gerar um zip com todos os arquivos criados, execute a c√©lula abaixo."
      ]
    },
    {
      "metadata": {
        "id": "2fe3gwncAwL1",
        "colab_type": "code",
        "outputId": "895b9a72-f6f4-4e94-9e26-5ebdf33ac9ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "rm -f cuda_files.zip\n",
        "zip -r cuda_files.zip . -i exemplo*.*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: exemplo5.cu (deflated 63%)\n",
            "  adding: exemplo4.cu (deflated 53%)\n",
            "  adding: exemplo1.cu (deflated 31%)\n",
            "  adding: exemplo3.cu (deflated 64%)\n",
            "  adding: exemplo7.cu (deflated 65%)\n",
            "  adding: exemplo2.cu (deflated 52%)\n",
            "  adding: exemplo6.cu (deflated 51%)\n",
            "  adding: exemplo7 (1).cu (deflated 65%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dkm0WZogUttd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download a file"
      ]
    },
    {
      "metadata": {
        "id": "x4ds4AfvUnLf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('cuda_files.zip') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q5l1qxflTsJB",
        "colab_type": "code",
        "outputId": "1183a0a5-4fc2-441d-d76c-605a360aefc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " cuda_files.zip   exemplo3.cu\t exemplo4_out   exemplo6.cu\t   exemplo7.cu\n",
            " exemplo1.cu\t  exemplo3_out\t exemplo5.cu    exemplo6_out\t   exemplo7_out\n",
            " exemplo2.cu\t  exemplo4.cu\t exemplo5_out  'exemplo7 (1).cu'   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0aNp6dOyAwL5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Depois de ** executar a c√©lula acima, voc√™ pode baixar o arquivo zip [here](cuda_files.zip)"
      ]
    }
  ]
}