{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Previsoes-Series-Temporais.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/Alunos-UEPB-BancoDeDados/blob/master/LST/Previsoes_Series_Temporais-Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8xkVKhTmjKHh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# <font color='blue'>Data Science Academy - Deep Learning II</font>"
      ]
    },
    {
      "metadata": {
        "id": "CuHq7Ep_jKHi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Previsões com Séries Temporais e RNNs "
      ]
    },
    {
      "metadata": {
        "id": "DLn3I9ZAjKHl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Carregando os Dados\n",
        "\n",
        "Primeiro, devemos carregar nossas séries temporais - uma série histórica de cerca de 140 dias do preço das ações da Apple (extraído do site DataMarket - https://datamarket.com/data/list/?q=provider%3Atsdl). Em seguida, precisamos executar uma série de etapas de pré-processamento para preparar os dados para uso com um modelo RNN. \n",
        "\n",
        "É uma boa prática normalizar as séries temporais - normalizando seu range. Isso nos ajuda a evitar problemas numéricos sérios associados a funções de ativação comuns (como o tanh) que transformam números muito grandes (positivos ou negativos), além de ajudar a evitar problemas relacionados ao computar derivadas.\n",
        "\n",
        "Aqui nós normalizamos a série para ficar na faixa [0,1], mas é também é comum normalizar por um desvio padrão da série."
      ]
    },
    {
      "metadata": {
        "id": "C0uqiwiWjKHm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ec5a7d4-21dd-47c1-87e6-a65867725976"
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3jhcOmvHjKHu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "21e0e17b-984b-4782-bfc5-7723d9d4d673"
      },
      "cell_type": "code",
      "source": [
        "!mkdir datasets\n",
        "!wget https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/LSTM/data/normalized_apple_prices.csv\n",
        "!wget https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/LSTM/data/apple_prices.csv\n",
        "!mv *.csv datasets\n",
        "dataset = np.loadtxt('datasets/normalized_apple_prices.csv')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-24 11:13:12--  https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/LSTM/data/normalized_apple_prices.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3536 (3.5K) [text/plain]\n",
            "Saving to: ‘normalized_apple_prices.csv’\n",
            "\n",
            "\r          normalize   0%[                    ]       0  --.-KB/s               \rnormalized_apple_pr 100%[===================>]   3.45K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-01-24 11:13:13 (77.1 MB/s) - ‘normalized_apple_prices.csv’ saved [3536/3536]\n",
            "\n",
            "--2019-01-24 11:13:15--  https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/LSTM/data/apple_prices.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1434 (1.4K) [text/plain]\n",
            "Saving to: ‘apple_prices.csv’\n",
            "\n",
            "apple_prices.csv    100%[===================>]   1.40K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-01-24 11:13:15 (237 MB/s) - ‘apple_prices.csv’ saved [1434/1434]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HvcxHKzrjKHy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "c33f33b5-73bf-4c95-b2f1-334f0bff7c92"
      },
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "plt.plot(dataset)\n",
        "plt.xlabel('Período de Tempo')\n",
        "plt.ylabel('Valores Normalizados da Série')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Valores Normalizados da Série')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsRARkYJULEREpKD/A0w470GW9GPXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "scf7DbjAjKH3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Extraindo Sequências da Série Temporal"
      ]
    },
    {
      "metadata": {
        "id": "Vr0HZ0OyjKH4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lembre-se, nossa série de tempo é uma sequência de números que podemos representar em termos matemáticos, como:\n",
        "\n",
        "$$s_{0},s_{1},s_{2},...,s_{P}$$\n",
        "\n",
        "onde $ s_ {p} $ é o valor numérico das séries temporais no período de tempo $ p $ e onde $ P $ é o comprimento total da série. Para aplicar nossa RNN tratamos o problema de previsão de séries temporais como um problema de regressão e, portanto, precisamos usar uma janela deslizante para construir um conjunto de pares de entrada / saída associados para regredir. Este processo é representado no gif abaixo.\n",
        "\n",
        "<img src=\"https://github.com/vladimiralencar/DeepLearning-LANA/raw/master/LSTM/images/timeseries_windowing_training.gif\" width=600 height=600/>\n",
        "\n",
        "Por exemplo - usando uma janela de tamanho T = 5 (como ilustrado no gif acima) produzimos um conjunto de pares de entrada / saída como o mostrado na tabela abaixo\n",
        "\n",
        "$$\n",
        "\\begin{array}{c|c}\n",
        "\\text{Input} & \\text{Output}\\\\\n",
        "\\hline \\color{CornflowerBlue} {\\langle s_{1},s_{2},s_{3},s_{4},s_{5}\\rangle} & \\color{Goldenrod}{ s_{6}} \\\\\n",
        "\\ \\color{CornflowerBlue} {\\langle s_{2},s_{3},s_{4},s_{5},s_{6} \\rangle } & \\color{Goldenrod} {s_{7} } \\\\\n",
        "\\color{CornflowerBlue}  {\\vdots} & \\color{Goldenrod} {\\vdots}\\\\\n",
        "\\color{CornflowerBlue} { \\langle s_{P-5},s_{P-4},s_{P-3},s_{P-2},s_{P-1} \\rangle } & \\color{Goldenrod} {s_{P}}\n",
        "\\end{array}$$\n",
        "\n",
        "Observe aqui que cada entrada é uma sequência (ou vetor) de comprimento 4 (e em geral tem um comprimento igual ao tamanho da janela T), enquanto cada saída correspondente é um valor escalar. Observe também como é dada uma série de tempo de comprimento P e tamanho de janela T = 5 como mostrado acima, criamos pares de entrada / saída P-5. De forma mais geral, para um tamanho de janela T, criamos P-T desses pares.\n",
        "\n",
        "Abaixo, temos uma função que cria essa janela deslizante."
      ]
    },
    {
      "metadata": {
        "id": "XezNuAuFjKH5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Função que transforma séries e window-size em um conjunto de input/output para o modelo RNN \n",
        "def window_transform_series(series, window_size):\n",
        "    \"\"\"\n",
        "      Argumentos:\n",
        "        series(np.array(list)): Sequência de valores\n",
        "        window_size(int      ): Tamanho da janela\n",
        "      \n",
        "      Retorna:\n",
        "         X(np.array(list(list))): Matriz de Input\n",
        "         y(np.array(list))      : Array de Ouput\n",
        "    \"\"\"\n",
        "\n",
        "    # Objetos para input/output \n",
        "    X = np.asarray([series[i:(i + window_size)] for i in range(len(series) - window_size)])\n",
        "    y = np.asarray([series[i + window_size] for i in range(len(series) - window_size)])\n",
        "\n",
        "    return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oLtXUWo4jKH9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aplicamos a função ao nosso conjunto de dados e definimos um windows-size = 7."
      ]
    },
    {
      "metadata": {
        "id": "3LSlCP7pjKH_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "window_size = 7\n",
        "X,y = window_transform_series(series = dataset, window_size = window_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMnf3H8ZjKIC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "165aff32-d1b6-4a92-d452-c6a2b680301a"
      },
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "K8xT7XazjKIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ddd82d84-ce16-4b48-ef5a-e9225f08e978"
      },
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.70062339, -0.82088484, -0.93938305, -0.9471652 , -0.68785527,\n",
              "       -0.84325902, -0.80532018])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "UAuFxDt6jKIL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dados de Treino e de Teste"
      ]
    },
    {
      "metadata": {
        "id": "_7-iJoQSjKIN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para realizar testes adequados em nosso conjunto de dados, usaremos o último 1/3 dele para teste. Isto é, uma vez que treinamos nosso modelo, temos algo para testá-lo (como qualquer problema de regressão!). Esta divisão em conjuntos de treinamento/teste é feita na célula abaixo.\n",
        "\n",
        "Observe como aqui ** não ** estamos dividindo o conjunto de dados * aleatoriamente * como normalmente seria feito ao validar um modelo de regressão. Isso ocorre porque nossos pares de entrada/saída * estão relacionados temporariamente *. Não queremos validar o nosso modelo treinando em um subconjunto aleatório da série e depois testar em outro subconjunto aleatório.\n",
        "\n",
        "Queremos treinar em um pedaço sólido da série (no nosso caso, os primeiros 2/3 completos), e validar em um pedaço posterior (o último 1/3), pois isso simula como prevermos os valores do * futuro * de uma série temporal."
      ]
    },
    {
      "metadata": {
        "id": "V0mErjEfjKIO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split em treino e teste\n",
        "train_test_split = int(np.ceil(2*len(y)/float(3)))  # Ponto de spplit\n",
        "\n",
        "# Particiona os dados de treino em X e Y\n",
        "X_train = X[:train_test_split,:]\n",
        "y_train = y[:train_test_split]\n",
        "\n",
        "# Particiona os dados de teste em X e Y\n",
        "X_test = X[train_test_split:,:]\n",
        "y_test = y[train_test_split:]\n",
        "\n",
        "# Para criar o Modelo RNN LSTM com o Keras nossos dados precisam estar no formato [samples, window size, stepsize] \n",
        "X_train = np.asarray(np.reshape(X_train, (X_train.shape[0], window_size, 1)))\n",
        "X_test = np.asarray(np.reshape(X_test, (X_test.shape[0], window_size, 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0bAVlpu1jKIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "354dfb31-3d04-4d00-a2a9-164f76252a86"
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88, 7, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "BYHfCwIejKIW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8972646f-a27b-4598-f3e7-4de8f0e6b8c1"
      },
      "cell_type": "code",
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.70062339]\n",
            " [-0.82088484]\n",
            " [-0.93938305]\n",
            " [-0.9471652 ]\n",
            " [-0.68785527]\n",
            " [-0.84325902]\n",
            " [-0.80532018]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ep2Z_TcHjKIb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Construindo o Modelo RNN"
      ]
    },
    {
      "metadata": {
        "id": "ce9QGAfljKId",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tendo criado pares de entrada / saída de nossas séries temporais e dividido em conjuntos de treinamento / teste, agora podemos começar a configurar nossa RNN. Usamos o Keras para criar rapidamente uma RNN de duas camadas ocultas com as  seguintes especificações\n",
        "\n",
        "- A camada 1 usa um módulo LSTM com 5 unidades escondidas (observe aqui o input_shape = (window_size, 1))\n",
        "- A camada 2 usa um módulo totalmente conectado com uma unidade\n",
        "- A perda 'mean_squared_error' deve ser usada (lembre-se: estamos realizando regressão aqui)"
      ]
    },
    {
      "metadata": {
        "id": "gknqP3hCjKIf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# RNN para regressão em nossos dados de séries temporais \n",
        "def build_RNN(window_size):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(5, input_shape=(window_size,1)))\n",
        "    model.add(Dense(1))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cIkUgS2IjKIl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cria e compila o modelo\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import keras\n",
        "\n",
        "# Random seed\n",
        "np.random.seed(0)\n",
        "\n",
        "# Build do modelo\n",
        "model = build_RNN(window_size)\n",
        "\n",
        "# Otimizador\n",
        "optimizer = keras.optimizers.RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-08, decay = 0.0)\n",
        "\n",
        "# Compila o modelo\n",
        "model.compile(loss = 'mean_squared_error', optimizer = optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xx-nvTIDjKIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d5be1d4c-e2c3-415c-e704-2d0905b0bac7"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 5)                 140       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 146\n",
            "Trainable params: 146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cgJXaeF7jKIy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fit do modelo"
      ]
    },
    {
      "metadata": {
        "id": "aRmRA5M8jKI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34034
        },
        "outputId": "4a6f7248-12ff-4827-c3b3-42276882f891"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs = 1000, batch_size = 50, verbose = 1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "88/88 [==============================] - 1s 12ms/step - loss: 0.1422\n",
            "Epoch 2/1000\n",
            "88/88 [==============================] - 0s 424us/step - loss: 0.1343\n",
            "Epoch 3/1000\n",
            "88/88 [==============================] - 0s 440us/step - loss: 0.1290\n",
            "Epoch 4/1000\n",
            "88/88 [==============================] - 0s 428us/step - loss: 0.1245\n",
            "Epoch 5/1000\n",
            "88/88 [==============================] - 0s 465us/step - loss: 0.1205\n",
            "Epoch 6/1000\n",
            "88/88 [==============================] - 0s 504us/step - loss: 0.1169\n",
            "Epoch 7/1000\n",
            "88/88 [==============================] - 0s 441us/step - loss: 0.1138\n",
            "Epoch 8/1000\n",
            "88/88 [==============================] - 0s 411us/step - loss: 0.1106\n",
            "Epoch 9/1000\n",
            "88/88 [==============================] - 0s 426us/step - loss: 0.1079\n",
            "Epoch 10/1000\n",
            "88/88 [==============================] - 0s 416us/step - loss: 0.1051\n",
            "Epoch 11/1000\n",
            "88/88 [==============================] - 0s 434us/step - loss: 0.1021\n",
            "Epoch 12/1000\n",
            "88/88 [==============================] - 0s 459us/step - loss: 0.0994\n",
            "Epoch 13/1000\n",
            "88/88 [==============================] - 0s 444us/step - loss: 0.0967\n",
            "Epoch 14/1000\n",
            "88/88 [==============================] - 0s 445us/step - loss: 0.0944\n",
            "Epoch 15/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0917\n",
            "Epoch 16/1000\n",
            "88/88 [==============================] - 0s 445us/step - loss: 0.0893\n",
            "Epoch 17/1000\n",
            "88/88 [==============================] - 0s 457us/step - loss: 0.0869\n",
            "Epoch 18/1000\n",
            "88/88 [==============================] - 0s 427us/step - loss: 0.0846\n",
            "Epoch 19/1000\n",
            "88/88 [==============================] - 0s 451us/step - loss: 0.0823\n",
            "Epoch 20/1000\n",
            "88/88 [==============================] - 0s 612us/step - loss: 0.0802\n",
            "Epoch 21/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0781\n",
            "Epoch 22/1000\n",
            "88/88 [==============================] - 0s 501us/step - loss: 0.0762\n",
            "Epoch 23/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0740\n",
            "Epoch 24/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0721\n",
            "Epoch 25/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0702\n",
            "Epoch 26/1000\n",
            "88/88 [==============================] - 0s 525us/step - loss: 0.0685\n",
            "Epoch 27/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0667\n",
            "Epoch 28/1000\n",
            "88/88 [==============================] - 0s 500us/step - loss: 0.0651\n",
            "Epoch 29/1000\n",
            "88/88 [==============================] - 0s 520us/step - loss: 0.0635\n",
            "Epoch 30/1000\n",
            "88/88 [==============================] - 0s 510us/step - loss: 0.0621\n",
            "Epoch 31/1000\n",
            "88/88 [==============================] - 0s 518us/step - loss: 0.0608\n",
            "Epoch 32/1000\n",
            "88/88 [==============================] - 0s 509us/step - loss: 0.0592\n",
            "Epoch 33/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0580\n",
            "Epoch 34/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0568\n",
            "Epoch 35/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0557\n",
            "Epoch 36/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0546\n",
            "Epoch 37/1000\n",
            "88/88 [==============================] - 0s 593us/step - loss: 0.0536\n",
            "Epoch 38/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0528\n",
            "Epoch 39/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0518\n",
            "Epoch 40/1000\n",
            "88/88 [==============================] - 0s 516us/step - loss: 0.0511\n",
            "Epoch 41/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0504\n",
            "Epoch 42/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0498\n",
            "Epoch 43/1000\n",
            "88/88 [==============================] - 0s 611us/step - loss: 0.0491\n",
            "Epoch 44/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0486\n",
            "Epoch 45/1000\n",
            "88/88 [==============================] - 0s 529us/step - loss: 0.0481\n",
            "Epoch 46/1000\n",
            "88/88 [==============================] - 0s 475us/step - loss: 0.0477\n",
            "Epoch 47/1000\n",
            "88/88 [==============================] - 0s 497us/step - loss: 0.0473\n",
            "Epoch 48/1000\n",
            "88/88 [==============================] - 0s 539us/step - loss: 0.0469\n",
            "Epoch 49/1000\n",
            "88/88 [==============================] - 0s 509us/step - loss: 0.0466\n",
            "Epoch 50/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0465\n",
            "Epoch 51/1000\n",
            "88/88 [==============================] - 0s 460us/step - loss: 0.0462\n",
            "Epoch 52/1000\n",
            "88/88 [==============================] - 0s 509us/step - loss: 0.0457\n",
            "Epoch 53/1000\n",
            "88/88 [==============================] - 0s 523us/step - loss: 0.0456\n",
            "Epoch 54/1000\n",
            "88/88 [==============================] - 0s 506us/step - loss: 0.0452\n",
            "Epoch 55/1000\n",
            "88/88 [==============================] - 0s 466us/step - loss: 0.0451\n",
            "Epoch 56/1000\n",
            "88/88 [==============================] - 0s 456us/step - loss: 0.0448\n",
            "Epoch 57/1000\n",
            "88/88 [==============================] - 0s 531us/step - loss: 0.0447\n",
            "Epoch 58/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0443\n",
            "Epoch 59/1000\n",
            "88/88 [==============================] - 0s 456us/step - loss: 0.0443\n",
            "Epoch 60/1000\n",
            "88/88 [==============================] - 0s 452us/step - loss: 0.0441\n",
            "Epoch 61/1000\n",
            "88/88 [==============================] - 0s 460us/step - loss: 0.0438\n",
            "Epoch 62/1000\n",
            "88/88 [==============================] - 0s 465us/step - loss: 0.0436\n",
            "Epoch 63/1000\n",
            "88/88 [==============================] - 0s 455us/step - loss: 0.0434\n",
            "Epoch 64/1000\n",
            "88/88 [==============================] - 0s 445us/step - loss: 0.0432\n",
            "Epoch 65/1000\n",
            "88/88 [==============================] - 0s 561us/step - loss: 0.0429\n",
            "Epoch 66/1000\n",
            "88/88 [==============================] - 0s 595us/step - loss: 0.0427\n",
            "Epoch 67/1000\n",
            "88/88 [==============================] - 0s 464us/step - loss: 0.0426\n",
            "Epoch 68/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0423\n",
            "Epoch 69/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0421\n",
            "Epoch 70/1000\n",
            "88/88 [==============================] - 0s 463us/step - loss: 0.0419\n",
            "Epoch 71/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0417\n",
            "Epoch 72/1000\n",
            "88/88 [==============================] - 0s 470us/step - loss: 0.0414\n",
            "Epoch 73/1000\n",
            "88/88 [==============================] - 0s 524us/step - loss: 0.0413\n",
            "Epoch 74/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0411\n",
            "Epoch 75/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0408\n",
            "Epoch 76/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0406\n",
            "Epoch 77/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0404\n",
            "Epoch 78/1000\n",
            "88/88 [==============================] - 0s 452us/step - loss: 0.0403\n",
            "Epoch 79/1000\n",
            "88/88 [==============================] - 0s 513us/step - loss: 0.0400\n",
            "Epoch 80/1000\n",
            "88/88 [==============================] - 0s 512us/step - loss: 0.0399\n",
            "Epoch 81/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0396\n",
            "Epoch 82/1000\n",
            "88/88 [==============================] - 0s 526us/step - loss: 0.0393\n",
            "Epoch 83/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0392\n",
            "Epoch 84/1000\n",
            "88/88 [==============================] - 0s 549us/step - loss: 0.0391\n",
            "Epoch 85/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0389\n",
            "Epoch 86/1000\n",
            "88/88 [==============================] - 0s 475us/step - loss: 0.0387\n",
            "Epoch 87/1000\n",
            "88/88 [==============================] - 0s 513us/step - loss: 0.0384\n",
            "Epoch 88/1000\n",
            "88/88 [==============================] - 0s 610us/step - loss: 0.0383\n",
            "Epoch 89/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0380\n",
            "Epoch 90/1000\n",
            "88/88 [==============================] - 0s 511us/step - loss: 0.0382\n",
            "Epoch 91/1000\n",
            "88/88 [==============================] - 0s 543us/step - loss: 0.0376\n",
            "Epoch 92/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0376\n",
            "Epoch 93/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0375\n",
            "Epoch 94/1000\n",
            "88/88 [==============================] - 0s 488us/step - loss: 0.0372\n",
            "Epoch 95/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0374\n",
            "Epoch 96/1000\n",
            "88/88 [==============================] - 0s 496us/step - loss: 0.0370\n",
            "Epoch 97/1000\n",
            "88/88 [==============================] - 0s 499us/step - loss: 0.0370\n",
            "Epoch 98/1000\n",
            "88/88 [==============================] - 0s 520us/step - loss: 0.0367\n",
            "Epoch 99/1000\n",
            "88/88 [==============================] - 0s 525us/step - loss: 0.0367\n",
            "Epoch 100/1000\n",
            "88/88 [==============================] - 0s 504us/step - loss: 0.0364\n",
            "Epoch 101/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0363\n",
            "Epoch 102/1000\n",
            "88/88 [==============================] - 0s 568us/step - loss: 0.0361\n",
            "Epoch 103/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0360\n",
            "Epoch 104/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0358\n",
            "Epoch 105/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0357\n",
            "Epoch 106/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0355\n",
            "Epoch 107/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0354\n",
            "Epoch 108/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0352\n",
            "Epoch 109/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0350\n",
            "Epoch 110/1000\n",
            "88/88 [==============================] - 0s 547us/step - loss: 0.0350\n",
            "Epoch 111/1000\n",
            "88/88 [==============================] - 0s 596us/step - loss: 0.0346\n",
            "Epoch 112/1000\n",
            "88/88 [==============================] - 0s 504us/step - loss: 0.0345\n",
            "Epoch 113/1000\n",
            "88/88 [==============================] - 0s 472us/step - loss: 0.0343\n",
            "Epoch 114/1000\n",
            "88/88 [==============================] - 0s 464us/step - loss: 0.0341\n",
            "Epoch 115/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0342\n",
            "Epoch 116/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0339\n",
            "Epoch 117/1000\n",
            "88/88 [==============================] - 0s 524us/step - loss: 0.0338\n",
            "Epoch 118/1000\n",
            "88/88 [==============================] - 0s 601us/step - loss: 0.0336\n",
            "Epoch 119/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0336\n",
            "Epoch 120/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0332\n",
            "Epoch 121/1000\n",
            "88/88 [==============================] - 0s 475us/step - loss: 0.0332\n",
            "Epoch 122/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0329\n",
            "Epoch 123/1000\n",
            "88/88 [==============================] - 0s 456us/step - loss: 0.0328\n",
            "Epoch 124/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0326\n",
            "Epoch 125/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0325\n",
            "Epoch 126/1000\n",
            "88/88 [==============================] - 0s 504us/step - loss: 0.0323\n",
            "Epoch 127/1000\n",
            "88/88 [==============================] - 0s 521us/step - loss: 0.0322\n",
            "Epoch 128/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0320\n",
            "Epoch 129/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0320\n",
            "Epoch 130/1000\n",
            "88/88 [==============================] - 0s 506us/step - loss: 0.0318\n",
            "Epoch 131/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0315\n",
            "Epoch 132/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0313\n",
            "Epoch 133/1000\n",
            "88/88 [==============================] - 0s 543us/step - loss: 0.0314\n",
            "Epoch 134/1000\n",
            "88/88 [==============================] - 0s 505us/step - loss: 0.0315\n",
            "Epoch 135/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0309\n",
            "Epoch 136/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0308\n",
            "Epoch 137/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0308\n",
            "Epoch 138/1000\n",
            "88/88 [==============================] - 0s 510us/step - loss: 0.0306\n",
            "Epoch 139/1000\n",
            "88/88 [==============================] - 0s 460us/step - loss: 0.0304\n",
            "Epoch 140/1000\n",
            "88/88 [==============================] - 0s 505us/step - loss: 0.0303\n",
            "Epoch 141/1000\n",
            "88/88 [==============================] - 0s 505us/step - loss: 0.0301\n",
            "Epoch 142/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0301\n",
            "Epoch 143/1000\n",
            "88/88 [==============================] - 0s 455us/step - loss: 0.0299\n",
            "Epoch 144/1000\n",
            "88/88 [==============================] - 0s 516us/step - loss: 0.0297\n",
            "Epoch 145/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0296\n",
            "Epoch 146/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0294\n",
            "Epoch 147/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0295\n",
            "Epoch 148/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0291\n",
            "Epoch 149/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0290\n",
            "Epoch 150/1000\n",
            "88/88 [==============================] - 0s 527us/step - loss: 0.0289\n",
            "Epoch 151/1000\n",
            "88/88 [==============================] - 0s 518us/step - loss: 0.0287\n",
            "Epoch 152/1000\n",
            "88/88 [==============================] - 0s 500us/step - loss: 0.0286\n",
            "Epoch 153/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0287\n",
            "Epoch 154/1000\n",
            "88/88 [==============================] - 0s 508us/step - loss: 0.0284\n",
            "Epoch 155/1000\n",
            "88/88 [==============================] - 0s 527us/step - loss: 0.0282\n",
            "Epoch 156/1000\n",
            "88/88 [==============================] - 0s 719us/step - loss: 0.0280\n",
            "Epoch 157/1000\n",
            "88/88 [==============================] - 0s 563us/step - loss: 0.0280\n",
            "Epoch 158/1000\n",
            "88/88 [==============================] - 0s 514us/step - loss: 0.0278\n",
            "Epoch 159/1000\n",
            "88/88 [==============================] - 0s 470us/step - loss: 0.0276\n",
            "Epoch 160/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0277\n",
            "Epoch 161/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0275\n",
            "Epoch 162/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0275\n",
            "Epoch 163/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0272\n",
            "Epoch 164/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0270\n",
            "Epoch 165/1000\n",
            "88/88 [==============================] - 0s 453us/step - loss: 0.0270\n",
            "Epoch 166/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0269\n",
            "Epoch 167/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0268\n",
            "Epoch 168/1000\n",
            "88/88 [==============================] - 0s 499us/step - loss: 0.0266\n",
            "Epoch 169/1000\n",
            "88/88 [==============================] - 0s 505us/step - loss: 0.0265\n",
            "Epoch 170/1000\n",
            "88/88 [==============================] - 0s 530us/step - loss: 0.0265\n",
            "Epoch 171/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0263\n",
            "Epoch 172/1000\n",
            "88/88 [==============================] - 0s 458us/step - loss: 0.0264\n",
            "Epoch 173/1000\n",
            "88/88 [==============================] - 0s 536us/step - loss: 0.0262\n",
            "Epoch 174/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0259\n",
            "Epoch 175/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0259\n",
            "Epoch 176/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0258\n",
            "Epoch 177/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0256\n",
            "Epoch 178/1000\n",
            "88/88 [==============================] - 0s 630us/step - loss: 0.0256\n",
            "Epoch 179/1000\n",
            "88/88 [==============================] - 0s 553us/step - loss: 0.0254\n",
            "Epoch 180/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0254\n",
            "Epoch 181/1000\n",
            "88/88 [==============================] - 0s 499us/step - loss: 0.0253\n",
            "Epoch 182/1000\n",
            "88/88 [==============================] - 0s 540us/step - loss: 0.0251\n",
            "Epoch 183/1000\n",
            "88/88 [==============================] - 0s 496us/step - loss: 0.0252\n",
            "Epoch 184/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0249\n",
            "Epoch 185/1000\n",
            "88/88 [==============================] - 0s 572us/step - loss: 0.0248\n",
            "Epoch 186/1000\n",
            "88/88 [==============================] - 0s 502us/step - loss: 0.0249\n",
            "Epoch 187/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0245\n",
            "Epoch 188/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0244\n",
            "Epoch 189/1000\n",
            "88/88 [==============================] - 0s 510us/step - loss: 0.0244\n",
            "Epoch 190/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0242\n",
            "Epoch 191/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0241\n",
            "Epoch 192/1000\n",
            "88/88 [==============================] - 0s 454us/step - loss: 0.0240\n",
            "Epoch 193/1000\n",
            "88/88 [==============================] - 0s 510us/step - loss: 0.0239\n",
            "Epoch 194/1000\n",
            "88/88 [==============================] - 0s 532us/step - loss: 0.0241\n",
            "Epoch 195/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0238\n",
            "Epoch 196/1000\n",
            "88/88 [==============================] - 0s 466us/step - loss: 0.0237\n",
            "Epoch 197/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0235\n",
            "Epoch 198/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0234\n",
            "Epoch 199/1000\n",
            "88/88 [==============================] - 0s 453us/step - loss: 0.0233\n",
            "Epoch 200/1000\n",
            "88/88 [==============================] - 0s 570us/step - loss: 0.0231\n",
            "Epoch 201/1000\n",
            "88/88 [==============================] - 0s 560us/step - loss: 0.0231\n",
            "Epoch 202/1000\n",
            "88/88 [==============================] - 0s 463us/step - loss: 0.0229\n",
            "Epoch 203/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0229\n",
            "Epoch 204/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0228\n",
            "Epoch 205/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0228\n",
            "Epoch 206/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0226\n",
            "Epoch 207/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0224\n",
            "Epoch 208/1000\n",
            "88/88 [==============================] - 0s 471us/step - loss: 0.0223\n",
            "Epoch 209/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0222\n",
            "Epoch 210/1000\n",
            "88/88 [==============================] - 0s 522us/step - loss: 0.0223\n",
            "Epoch 211/1000\n",
            "88/88 [==============================] - 0s 504us/step - loss: 0.0221\n",
            "Epoch 212/1000\n",
            "88/88 [==============================] - 0s 461us/step - loss: 0.0219\n",
            "Epoch 213/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0220\n",
            "Epoch 214/1000\n",
            "88/88 [==============================] - 0s 528us/step - loss: 0.0217\n",
            "Epoch 215/1000\n",
            "88/88 [==============================] - 0s 501us/step - loss: 0.0219\n",
            "Epoch 216/1000\n",
            "88/88 [==============================] - 0s 527us/step - loss: 0.0216\n",
            "Epoch 217/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0216\n",
            "Epoch 218/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0217\n",
            "Epoch 219/1000\n",
            "88/88 [==============================] - 0s 515us/step - loss: 0.0215\n",
            "Epoch 220/1000\n",
            "88/88 [==============================] - 0s 503us/step - loss: 0.0213\n",
            "Epoch 221/1000\n",
            "88/88 [==============================] - 0s 448us/step - loss: 0.0213\n",
            "Epoch 222/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0211\n",
            "Epoch 223/1000\n",
            "88/88 [==============================] - 0s 609us/step - loss: 0.0211\n",
            "Epoch 224/1000\n",
            "88/88 [==============================] - 0s 511us/step - loss: 0.0211\n",
            "Epoch 225/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0209\n",
            "Epoch 226/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0212\n",
            "Epoch 227/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0208\n",
            "Epoch 228/1000\n",
            "88/88 [==============================] - 0s 446us/step - loss: 0.0207\n",
            "Epoch 229/1000\n",
            "88/88 [==============================] - 0s 510us/step - loss: 0.0207\n",
            "Epoch 230/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0206\n",
            "Epoch 231/1000\n",
            "88/88 [==============================] - 0s 462us/step - loss: 0.0205\n",
            "Epoch 232/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0205\n",
            "Epoch 233/1000\n",
            "88/88 [==============================] - 0s 454us/step - loss: 0.0203\n",
            "Epoch 234/1000\n",
            "88/88 [==============================] - 0s 452us/step - loss: 0.0206\n",
            "Epoch 235/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0202\n",
            "Epoch 236/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0201\n",
            "Epoch 237/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0201\n",
            "Epoch 238/1000\n",
            "88/88 [==============================] - 0s 446us/step - loss: 0.0200\n",
            "Epoch 239/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0199\n",
            "Epoch 240/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0202\n",
            "Epoch 241/1000\n",
            "88/88 [==============================] - 0s 471us/step - loss: 0.0198\n",
            "Epoch 242/1000\n",
            "88/88 [==============================] - 0s 615us/step - loss: 0.0197\n",
            "Epoch 243/1000\n",
            "88/88 [==============================] - 0s 536us/step - loss: 0.0198\n",
            "Epoch 244/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0196\n",
            "Epoch 245/1000\n",
            "88/88 [==============================] - 0s 503us/step - loss: 0.0197\n",
            "Epoch 246/1000\n",
            "88/88 [==============================] - 0s 574us/step - loss: 0.0196\n",
            "Epoch 247/1000\n",
            "88/88 [==============================] - 0s 553us/step - loss: 0.0195\n",
            "Epoch 248/1000\n",
            "88/88 [==============================] - 0s 520us/step - loss: 0.0196\n",
            "Epoch 249/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0194\n",
            "Epoch 250/1000\n",
            "88/88 [==============================] - 0s 496us/step - loss: 0.0196\n",
            "Epoch 251/1000\n",
            "88/88 [==============================] - 0s 488us/step - loss: 0.0192\n",
            "Epoch 252/1000\n",
            "88/88 [==============================] - 0s 505us/step - loss: 0.0192\n",
            "Epoch 253/1000\n",
            "88/88 [==============================] - 0s 462us/step - loss: 0.0192\n",
            "Epoch 254/1000\n",
            "88/88 [==============================] - 0s 460us/step - loss: 0.0191\n",
            "Epoch 255/1000\n",
            "88/88 [==============================] - 0s 470us/step - loss: 0.0193\n",
            "Epoch 256/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0190\n",
            "Epoch 257/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0190\n",
            "Epoch 258/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0190\n",
            "Epoch 259/1000\n",
            "88/88 [==============================] - 0s 524us/step - loss: 0.0189\n",
            "Epoch 260/1000\n",
            "88/88 [==============================] - 0s 510us/step - loss: 0.0188\n",
            "Epoch 261/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0191\n",
            "Epoch 262/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0190\n",
            "Epoch 263/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0187\n",
            "Epoch 264/1000\n",
            "88/88 [==============================] - 0s 427us/step - loss: 0.0187\n",
            "Epoch 265/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0186\n",
            "Epoch 266/1000\n",
            "88/88 [==============================] - 0s 506us/step - loss: 0.0188\n",
            "Epoch 267/1000\n",
            "88/88 [==============================] - 0s 583us/step - loss: 0.0186\n",
            "Epoch 268/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0188\n",
            "Epoch 269/1000\n",
            "88/88 [==============================] - 0s 652us/step - loss: 0.0186\n",
            "Epoch 270/1000\n",
            "88/88 [==============================] - 0s 507us/step - loss: 0.0184\n",
            "Epoch 271/1000\n",
            "88/88 [==============================] - 0s 419us/step - loss: 0.0187\n",
            "Epoch 272/1000\n",
            "88/88 [==============================] - 0s 472us/step - loss: 0.0184\n",
            "Epoch 273/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0184\n",
            "Epoch 274/1000\n",
            "88/88 [==============================] - 0s 459us/step - loss: 0.0183\n",
            "Epoch 275/1000\n",
            "88/88 [==============================] - 0s 466us/step - loss: 0.0183\n",
            "Epoch 276/1000\n",
            "88/88 [==============================] - 0s 435us/step - loss: 0.0183\n",
            "Epoch 277/1000\n",
            "88/88 [==============================] - 0s 508us/step - loss: 0.0186\n",
            "Epoch 278/1000\n",
            "88/88 [==============================] - 0s 488us/step - loss: 0.0182\n",
            "Epoch 279/1000\n",
            "88/88 [==============================] - 0s 472us/step - loss: 0.0183\n",
            "Epoch 280/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0181\n",
            "Epoch 281/1000\n",
            "88/88 [==============================] - 0s 443us/step - loss: 0.0181\n",
            "Epoch 282/1000\n",
            "88/88 [==============================] - 0s 465us/step - loss: 0.0183\n",
            "Epoch 283/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0183\n",
            "Epoch 284/1000\n",
            "88/88 [==============================] - 0s 456us/step - loss: 0.0181\n",
            "Epoch 285/1000\n",
            "88/88 [==============================] - 0s 470us/step - loss: 0.0180\n",
            "Epoch 286/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0182\n",
            "Epoch 287/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0180\n",
            "Epoch 288/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0180\n",
            "Epoch 289/1000\n",
            "88/88 [==============================] - 0s 453us/step - loss: 0.0180\n",
            "Epoch 290/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0180\n",
            "Epoch 291/1000\n",
            "88/88 [==============================] - 0s 460us/step - loss: 0.0180\n",
            "Epoch 292/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0179\n",
            "Epoch 293/1000\n",
            "88/88 [==============================] - 0s 640us/step - loss: 0.0179\n",
            "Epoch 294/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0179\n",
            "Epoch 295/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0179\n",
            "Epoch 296/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0180\n",
            "Epoch 297/1000\n",
            "88/88 [==============================] - 0s 453us/step - loss: 0.0179\n",
            "Epoch 298/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0179\n",
            "Epoch 299/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0177\n",
            "Epoch 300/1000\n",
            "88/88 [==============================] - 0s 565us/step - loss: 0.0177\n",
            "Epoch 301/1000\n",
            "88/88 [==============================] - 0s 528us/step - loss: 0.0178\n",
            "Epoch 302/1000\n",
            "88/88 [==============================] - 0s 516us/step - loss: 0.0177\n",
            "Epoch 303/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0179\n",
            "Epoch 304/1000\n",
            "88/88 [==============================] - 0s 497us/step - loss: 0.0176\n",
            "Epoch 305/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0177\n",
            "Epoch 306/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0178\n",
            "Epoch 307/1000\n",
            "88/88 [==============================] - 0s 532us/step - loss: 0.0178\n",
            "Epoch 308/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0176\n",
            "Epoch 309/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0176\n",
            "Epoch 310/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0178\n",
            "Epoch 311/1000\n",
            "88/88 [==============================] - 0s 512us/step - loss: 0.0175\n",
            "Epoch 312/1000\n",
            "88/88 [==============================] - 0s 508us/step - loss: 0.0176\n",
            "Epoch 313/1000\n",
            "88/88 [==============================] - 0s 509us/step - loss: 0.0176\n",
            "Epoch 314/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0175\n",
            "Epoch 315/1000\n",
            "88/88 [==============================] - 0s 627us/step - loss: 0.0176\n",
            "Epoch 316/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0175\n",
            "Epoch 317/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0178\n",
            "Epoch 318/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0175\n",
            "Epoch 319/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0175\n",
            "Epoch 320/1000\n",
            "88/88 [==============================] - 0s 453us/step - loss: 0.0177\n",
            "Epoch 321/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0177\n",
            "Epoch 322/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0175\n",
            "Epoch 323/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0175\n",
            "Epoch 324/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0174\n",
            "Epoch 325/1000\n",
            "88/88 [==============================] - 0s 457us/step - loss: 0.0179\n",
            "Epoch 326/1000\n",
            "88/88 [==============================] - 0s 502us/step - loss: 0.0174\n",
            "Epoch 327/1000\n",
            "88/88 [==============================] - 0s 511us/step - loss: 0.0174\n",
            "Epoch 328/1000\n",
            "88/88 [==============================] - 0s 519us/step - loss: 0.0175\n",
            "Epoch 329/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0175\n",
            "Epoch 330/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0176\n",
            "Epoch 331/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0174\n",
            "Epoch 332/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0174\n",
            "Epoch 333/1000\n",
            "88/88 [==============================] - 0s 449us/step - loss: 0.0173\n",
            "Epoch 334/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0174\n",
            "Epoch 335/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0173\n",
            "Epoch 336/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0175\n",
            "Epoch 337/1000\n",
            "88/88 [==============================] - 0s 535us/step - loss: 0.0176\n",
            "Epoch 338/1000\n",
            "88/88 [==============================] - 0s 652us/step - loss: 0.0174\n",
            "Epoch 339/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0173\n",
            "Epoch 340/1000\n",
            "88/88 [==============================] - 0s 488us/step - loss: 0.0173\n",
            "Epoch 341/1000\n",
            "88/88 [==============================] - 0s 520us/step - loss: 0.0175\n",
            "Epoch 342/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0174\n",
            "Epoch 343/1000\n",
            "88/88 [==============================] - 0s 463us/step - loss: 0.0172\n",
            "Epoch 344/1000\n",
            "88/88 [==============================] - 0s 448us/step - loss: 0.0172\n",
            "Epoch 345/1000\n",
            "88/88 [==============================] - 0s 456us/step - loss: 0.0176\n",
            "Epoch 346/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0174\n",
            "Epoch 347/1000\n",
            "88/88 [==============================] - 0s 529us/step - loss: 0.0173\n",
            "Epoch 348/1000\n",
            "88/88 [==============================] - 0s 459us/step - loss: 0.0172\n",
            "Epoch 349/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0173\n",
            "Epoch 350/1000\n",
            "88/88 [==============================] - 0s 515us/step - loss: 0.0172\n",
            "Epoch 351/1000\n",
            "88/88 [==============================] - 0s 531us/step - loss: 0.0173\n",
            "Epoch 352/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0172\n",
            "Epoch 353/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0173\n",
            "Epoch 354/1000\n",
            "88/88 [==============================] - 0s 462us/step - loss: 0.0173\n",
            "Epoch 355/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0172\n",
            "Epoch 356/1000\n",
            "88/88 [==============================] - 0s 463us/step - loss: 0.0173\n",
            "Epoch 357/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0173\n",
            "Epoch 358/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0172\n",
            "Epoch 359/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0175\n",
            "Epoch 360/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0173\n",
            "Epoch 361/1000\n",
            "88/88 [==============================] - 0s 569us/step - loss: 0.0172\n",
            "Epoch 362/1000\n",
            "88/88 [==============================] - 0s 517us/step - loss: 0.0174\n",
            "Epoch 363/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0172\n",
            "Epoch 364/1000\n",
            "88/88 [==============================] - 0s 522us/step - loss: 0.0173\n",
            "Epoch 365/1000\n",
            "88/88 [==============================] - 0s 471us/step - loss: 0.0172\n",
            "Epoch 366/1000\n",
            "88/88 [==============================] - 0s 502us/step - loss: 0.0171\n",
            "Epoch 367/1000\n",
            "88/88 [==============================] - 0s 509us/step - loss: 0.0173\n",
            "Epoch 368/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0173\n",
            "Epoch 369/1000\n",
            "88/88 [==============================] - 0s 496us/step - loss: 0.0171\n",
            "Epoch 370/1000\n",
            "88/88 [==============================] - 0s 497us/step - loss: 0.0171\n",
            "Epoch 371/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0173\n",
            "Epoch 372/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0173\n",
            "Epoch 373/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0171\n",
            "Epoch 374/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0171\n",
            "Epoch 375/1000\n",
            "88/88 [==============================] - 0s 511us/step - loss: 0.0171\n",
            "Epoch 376/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0171\n",
            "Epoch 377/1000\n",
            "88/88 [==============================] - 0s 539us/step - loss: 0.0171\n",
            "Epoch 378/1000\n",
            "88/88 [==============================] - 0s 505us/step - loss: 0.0171\n",
            "Epoch 379/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0171\n",
            "Epoch 380/1000\n",
            "88/88 [==============================] - 0s 558us/step - loss: 0.0172\n",
            "Epoch 381/1000\n",
            "88/88 [==============================] - 0s 516us/step - loss: 0.0171\n",
            "Epoch 382/1000\n",
            "88/88 [==============================] - 0s 513us/step - loss: 0.0171\n",
            "Epoch 383/1000\n",
            "88/88 [==============================] - 0s 537us/step - loss: 0.0171\n",
            "Epoch 384/1000\n",
            "88/88 [==============================] - 0s 643us/step - loss: 0.0171\n",
            "Epoch 385/1000\n",
            "88/88 [==============================] - 0s 518us/step - loss: 0.0172\n",
            "Epoch 386/1000\n",
            "88/88 [==============================] - 0s 442us/step - loss: 0.0170\n",
            "Epoch 387/1000\n",
            "88/88 [==============================] - 0s 497us/step - loss: 0.0170\n",
            "Epoch 388/1000\n",
            "88/88 [==============================] - 0s 475us/step - loss: 0.0171\n",
            "Epoch 389/1000\n",
            "88/88 [==============================] - 0s 470us/step - loss: 0.0170\n",
            "Epoch 390/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0170\n",
            "Epoch 391/1000\n",
            "88/88 [==============================] - 0s 450us/step - loss: 0.0173\n",
            "Epoch 392/1000\n",
            "88/88 [==============================] - 0s 537us/step - loss: 0.0170\n",
            "Epoch 393/1000\n",
            "88/88 [==============================] - 0s 543us/step - loss: 0.0170\n",
            "Epoch 394/1000\n",
            "88/88 [==============================] - 0s 524us/step - loss: 0.0170\n",
            "Epoch 395/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0171\n",
            "Epoch 396/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0171\n",
            "Epoch 397/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0170\n",
            "Epoch 398/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0170\n",
            "Epoch 399/1000\n",
            "88/88 [==============================] - 0s 465us/step - loss: 0.0170\n",
            "Epoch 400/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0172\n",
            "Epoch 401/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0170\n",
            "Epoch 402/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0171\n",
            "Epoch 403/1000\n",
            "88/88 [==============================] - 0s 521us/step - loss: 0.0175\n",
            "Epoch 404/1000\n",
            "88/88 [==============================] - 0s 514us/step - loss: 0.0170\n",
            "Epoch 405/1000\n",
            "88/88 [==============================] - 0s 512us/step - loss: 0.0170\n",
            "Epoch 406/1000\n",
            "88/88 [==============================] - 0s 496us/step - loss: 0.0169\n",
            "Epoch 407/1000\n",
            "88/88 [==============================] - 0s 558us/step - loss: 0.0170\n",
            "Epoch 408/1000\n",
            "88/88 [==============================] - 0s 488us/step - loss: 0.0170\n",
            "Epoch 409/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0170\n",
            "Epoch 410/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0169\n",
            "Epoch 411/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0175\n",
            "Epoch 412/1000\n",
            "88/88 [==============================] - 0s 447us/step - loss: 0.0169\n",
            "Epoch 413/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0172\n",
            "Epoch 414/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0170\n",
            "Epoch 415/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0169\n",
            "Epoch 416/1000\n",
            "88/88 [==============================] - 0s 508us/step - loss: 0.0171\n",
            "Epoch 417/1000\n",
            "88/88 [==============================] - 0s 499us/step - loss: 0.0170\n",
            "Epoch 418/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0173\n",
            "Epoch 419/1000\n",
            "88/88 [==============================] - 0s 533us/step - loss: 0.0170\n",
            "Epoch 420/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0169\n",
            "Epoch 421/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0169\n",
            "Epoch 422/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0170\n",
            "Epoch 423/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0169\n",
            "Epoch 424/1000\n",
            "88/88 [==============================] - 0s 456us/step - loss: 0.0169\n",
            "Epoch 425/1000\n",
            "88/88 [==============================] - 0s 511us/step - loss: 0.0169\n",
            "Epoch 426/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0169\n",
            "Epoch 427/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0169\n",
            "Epoch 428/1000\n",
            "88/88 [==============================] - 0s 516us/step - loss: 0.0169\n",
            "Epoch 429/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0171\n",
            "Epoch 430/1000\n",
            "88/88 [==============================] - 0s 590us/step - loss: 0.0170\n",
            "Epoch 431/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0170\n",
            "Epoch 432/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0170\n",
            "Epoch 433/1000\n",
            "88/88 [==============================] - 0s 453us/step - loss: 0.0169\n",
            "Epoch 434/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0168\n",
            "Epoch 435/1000\n",
            "88/88 [==============================] - 0s 499us/step - loss: 0.0170\n",
            "Epoch 436/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0169\n",
            "Epoch 437/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0176\n",
            "Epoch 438/1000\n",
            "88/88 [==============================] - 0s 508us/step - loss: 0.0169\n",
            "Epoch 439/1000\n",
            "88/88 [==============================] - 0s 463us/step - loss: 0.0171\n",
            "Epoch 440/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0171\n",
            "Epoch 441/1000\n",
            "88/88 [==============================] - 0s 461us/step - loss: 0.0168\n",
            "Epoch 442/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0168\n",
            "Epoch 443/1000\n",
            "88/88 [==============================] - 0s 454us/step - loss: 0.0168\n",
            "Epoch 444/1000\n",
            "88/88 [==============================] - 0s 454us/step - loss: 0.0169\n",
            "Epoch 445/1000\n",
            "88/88 [==============================] - 0s 472us/step - loss: 0.0170\n",
            "Epoch 446/1000\n",
            "88/88 [==============================] - 0s 443us/step - loss: 0.0169\n",
            "Epoch 447/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0172\n",
            "Epoch 448/1000\n",
            "88/88 [==============================] - 0s 471us/step - loss: 0.0169\n",
            "Epoch 449/1000\n",
            "88/88 [==============================] - 0s 466us/step - loss: 0.0168\n",
            "Epoch 450/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0169\n",
            "Epoch 451/1000\n",
            "88/88 [==============================] - 0s 471us/step - loss: 0.0168\n",
            "Epoch 452/1000\n",
            "88/88 [==============================] - 0s 527us/step - loss: 0.0168\n",
            "Epoch 453/1000\n",
            "88/88 [==============================] - 0s 606us/step - loss: 0.0168\n",
            "Epoch 454/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0168\n",
            "Epoch 455/1000\n",
            "88/88 [==============================] - 0s 471us/step - loss: 0.0168\n",
            "Epoch 456/1000\n",
            "88/88 [==============================] - 0s 589us/step - loss: 0.0170\n",
            "Epoch 457/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0168\n",
            "Epoch 458/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0168\n",
            "Epoch 459/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0168\n",
            "Epoch 460/1000\n",
            "88/88 [==============================] - 0s 459us/step - loss: 0.0169\n",
            "Epoch 461/1000\n",
            "88/88 [==============================] - 0s 432us/step - loss: 0.0172\n",
            "Epoch 462/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0169\n",
            "Epoch 463/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0168\n",
            "Epoch 464/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0168\n",
            "Epoch 465/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0169\n",
            "Epoch 466/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0168\n",
            "Epoch 467/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0168\n",
            "Epoch 468/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0170\n",
            "Epoch 469/1000\n",
            "88/88 [==============================] - 0s 446us/step - loss: 0.0168\n",
            "Epoch 470/1000\n",
            "88/88 [==============================] - 0s 512us/step - loss: 0.0169\n",
            "Epoch 471/1000\n",
            "88/88 [==============================] - 0s 447us/step - loss: 0.0168\n",
            "Epoch 472/1000\n",
            "88/88 [==============================] - 0s 460us/step - loss: 0.0168\n",
            "Epoch 473/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0172\n",
            "Epoch 474/1000\n",
            "88/88 [==============================] - 0s 488us/step - loss: 0.0168\n",
            "Epoch 475/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0167\n",
            "Epoch 476/1000\n",
            "88/88 [==============================] - 0s 514us/step - loss: 0.0168\n",
            "Epoch 477/1000\n",
            "88/88 [==============================] - 0s 625us/step - loss: 0.0168\n",
            "Epoch 478/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0168\n",
            "Epoch 479/1000\n",
            "88/88 [==============================] - 0s 460us/step - loss: 0.0168\n",
            "Epoch 480/1000\n",
            "88/88 [==============================] - 0s 461us/step - loss: 0.0169\n",
            "Epoch 481/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0168\n",
            "Epoch 482/1000\n",
            "88/88 [==============================] - 0s 461us/step - loss: 0.0169\n",
            "Epoch 483/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0168\n",
            "Epoch 484/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0167\n",
            "Epoch 485/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0167\n",
            "Epoch 486/1000\n",
            "88/88 [==============================] - 0s 510us/step - loss: 0.0167\n",
            "Epoch 487/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0168\n",
            "Epoch 488/1000\n",
            "88/88 [==============================] - 0s 544us/step - loss: 0.0168\n",
            "Epoch 489/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0168\n",
            "Epoch 490/1000\n",
            "88/88 [==============================] - 0s 496us/step - loss: 0.0168\n",
            "Epoch 491/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0168\n",
            "Epoch 492/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0167\n",
            "Epoch 493/1000\n",
            "88/88 [==============================] - 0s 465us/step - loss: 0.0172\n",
            "Epoch 494/1000\n",
            "88/88 [==============================] - 0s 523us/step - loss: 0.0170\n",
            "Epoch 495/1000\n",
            "88/88 [==============================] - 0s 544us/step - loss: 0.0167\n",
            "Epoch 496/1000\n",
            "88/88 [==============================] - 0s 532us/step - loss: 0.0167\n",
            "Epoch 497/1000\n",
            "88/88 [==============================] - 0s 459us/step - loss: 0.0169\n",
            "Epoch 498/1000\n",
            "88/88 [==============================] - 0s 507us/step - loss: 0.0167\n",
            "Epoch 499/1000\n",
            "88/88 [==============================] - 0s 604us/step - loss: 0.0167\n",
            "Epoch 500/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0167\n",
            "Epoch 501/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0168\n",
            "Epoch 502/1000\n",
            "88/88 [==============================] - 0s 499us/step - loss: 0.0169\n",
            "Epoch 503/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0167\n",
            "Epoch 504/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0167\n",
            "Epoch 505/1000\n",
            "88/88 [==============================] - 0s 545us/step - loss: 0.0168\n",
            "Epoch 506/1000\n",
            "88/88 [==============================] - 0s 501us/step - loss: 0.0168\n",
            "Epoch 507/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0168\n",
            "Epoch 508/1000\n",
            "88/88 [==============================] - 0s 511us/step - loss: 0.0167\n",
            "Epoch 509/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0169\n",
            "Epoch 510/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0167\n",
            "Epoch 511/1000\n",
            "88/88 [==============================] - 0s 525us/step - loss: 0.0168\n",
            "Epoch 512/1000\n",
            "88/88 [==============================] - 0s 472us/step - loss: 0.0169\n",
            "Epoch 513/1000\n",
            "88/88 [==============================] - 0s 505us/step - loss: 0.0168\n",
            "Epoch 514/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0168\n",
            "Epoch 515/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0167\n",
            "Epoch 516/1000\n",
            "88/88 [==============================] - 0s 530us/step - loss: 0.0170\n",
            "Epoch 517/1000\n",
            "88/88 [==============================] - 0s 464us/step - loss: 0.0167\n",
            "Epoch 518/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0167\n",
            "Epoch 519/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0166\n",
            "Epoch 520/1000\n",
            "88/88 [==============================] - 0s 432us/step - loss: 0.0167\n",
            "Epoch 521/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0170\n",
            "Epoch 522/1000\n",
            "88/88 [==============================] - 0s 633us/step - loss: 0.0166\n",
            "Epoch 523/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0169\n",
            "Epoch 524/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0167\n",
            "Epoch 525/1000\n",
            "88/88 [==============================] - 0s 456us/step - loss: 0.0167\n",
            "Epoch 526/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0167\n",
            "Epoch 527/1000\n",
            "88/88 [==============================] - 0s 475us/step - loss: 0.0166\n",
            "Epoch 528/1000\n",
            "88/88 [==============================] - 0s 466us/step - loss: 0.0167\n",
            "Epoch 529/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0166\n",
            "Epoch 530/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0166\n",
            "Epoch 531/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0167\n",
            "Epoch 532/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0167\n",
            "Epoch 533/1000\n",
            "88/88 [==============================] - 0s 488us/step - loss: 0.0170\n",
            "Epoch 534/1000\n",
            "88/88 [==============================] - 0s 462us/step - loss: 0.0166\n",
            "Epoch 535/1000\n",
            "88/88 [==============================] - 0s 499us/step - loss: 0.0168\n",
            "Epoch 536/1000\n",
            "88/88 [==============================] - 0s 465us/step - loss: 0.0168\n",
            "Epoch 537/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0167\n",
            "Epoch 538/1000\n",
            "88/88 [==============================] - 0s 497us/step - loss: 0.0171\n",
            "Epoch 539/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0167\n",
            "Epoch 540/1000\n",
            "88/88 [==============================] - 0s 460us/step - loss: 0.0167\n",
            "Epoch 541/1000\n",
            "88/88 [==============================] - 0s 464us/step - loss: 0.0166\n",
            "Epoch 542/1000\n",
            "88/88 [==============================] - 0s 499us/step - loss: 0.0166\n",
            "Epoch 543/1000\n",
            "88/88 [==============================] - 0s 507us/step - loss: 0.0166\n",
            "Epoch 544/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0168\n",
            "Epoch 545/1000\n",
            "88/88 [==============================] - 0s 682us/step - loss: 0.0169\n",
            "Epoch 546/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0167\n",
            "Epoch 547/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0166\n",
            "Epoch 548/1000\n",
            "88/88 [==============================] - 0s 544us/step - loss: 0.0168\n",
            "Epoch 549/1000\n",
            "88/88 [==============================] - 0s 504us/step - loss: 0.0167\n",
            "Epoch 550/1000\n",
            "88/88 [==============================] - 0s 536us/step - loss: 0.0168\n",
            "Epoch 551/1000\n",
            "88/88 [==============================] - 0s 466us/step - loss: 0.0166\n",
            "Epoch 552/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0167\n",
            "Epoch 553/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0167\n",
            "Epoch 554/1000\n",
            "88/88 [==============================] - 0s 497us/step - loss: 0.0167\n",
            "Epoch 555/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0166\n",
            "Epoch 556/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0166\n",
            "Epoch 557/1000\n",
            "88/88 [==============================] - 0s 538us/step - loss: 0.0167\n",
            "Epoch 558/1000\n",
            "88/88 [==============================] - 0s 516us/step - loss: 0.0166\n",
            "Epoch 559/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0167\n",
            "Epoch 560/1000\n",
            "88/88 [==============================] - 0s 506us/step - loss: 0.0168\n",
            "Epoch 561/1000\n",
            "88/88 [==============================] - 0s 488us/step - loss: 0.0166\n",
            "Epoch 562/1000\n",
            "88/88 [==============================] - 0s 503us/step - loss: 0.0166\n",
            "Epoch 563/1000\n",
            "88/88 [==============================] - 0s 529us/step - loss: 0.0166\n",
            "Epoch 564/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0166\n",
            "Epoch 565/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0168\n",
            "Epoch 566/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0167\n",
            "Epoch 567/1000\n",
            "88/88 [==============================] - 0s 525us/step - loss: 0.0167\n",
            "Epoch 568/1000\n",
            "88/88 [==============================] - 0s 590us/step - loss: 0.0167\n",
            "Epoch 569/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0166\n",
            "Epoch 570/1000\n",
            "88/88 [==============================] - 0s 450us/step - loss: 0.0165\n",
            "Epoch 571/1000\n",
            "88/88 [==============================] - 0s 455us/step - loss: 0.0169\n",
            "Epoch 572/1000\n",
            "88/88 [==============================] - 0s 443us/step - loss: 0.0166\n",
            "Epoch 573/1000\n",
            "88/88 [==============================] - 0s 455us/step - loss: 0.0169\n",
            "Epoch 574/1000\n",
            "88/88 [==============================] - 0s 532us/step - loss: 0.0166\n",
            "Epoch 575/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0165\n",
            "Epoch 576/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0165\n",
            "Epoch 577/1000\n",
            "88/88 [==============================] - 0s 452us/step - loss: 0.0166\n",
            "Epoch 578/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0167\n",
            "Epoch 579/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0166\n",
            "Epoch 580/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0165\n",
            "Epoch 581/1000\n",
            "88/88 [==============================] - 0s 509us/step - loss: 0.0167\n",
            "Epoch 582/1000\n",
            "88/88 [==============================] - 0s 436us/step - loss: 0.0166\n",
            "Epoch 583/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0166\n",
            "Epoch 584/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0165\n",
            "Epoch 585/1000\n",
            "88/88 [==============================] - 0s 475us/step - loss: 0.0166\n",
            "Epoch 586/1000\n",
            "88/88 [==============================] - 0s 520us/step - loss: 0.0167\n",
            "Epoch 587/1000\n",
            "88/88 [==============================] - 0s 455us/step - loss: 0.0165\n",
            "Epoch 588/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0167\n",
            "Epoch 589/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0166\n",
            "Epoch 590/1000\n",
            "88/88 [==============================] - 0s 517us/step - loss: 0.0167\n",
            "Epoch 591/1000\n",
            "88/88 [==============================] - 0s 592us/step - loss: 0.0166\n",
            "Epoch 592/1000\n",
            "88/88 [==============================] - 0s 463us/step - loss: 0.0166\n",
            "Epoch 593/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0165\n",
            "Epoch 594/1000\n",
            "88/88 [==============================] - 0s 466us/step - loss: 0.0169\n",
            "Epoch 595/1000\n",
            "88/88 [==============================] - 0s 454us/step - loss: 0.0166\n",
            "Epoch 596/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0165\n",
            "Epoch 597/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0165\n",
            "Epoch 598/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0165\n",
            "Epoch 599/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0167\n",
            "Epoch 600/1000\n",
            "88/88 [==============================] - 0s 522us/step - loss: 0.0166\n",
            "Epoch 601/1000\n",
            "88/88 [==============================] - 0s 502us/step - loss: 0.0166\n",
            "Epoch 602/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0165\n",
            "Epoch 603/1000\n",
            "88/88 [==============================] - 0s 440us/step - loss: 0.0167\n",
            "Epoch 604/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0166\n",
            "Epoch 605/1000\n",
            "88/88 [==============================] - 0s 448us/step - loss: 0.0165\n",
            "Epoch 606/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0166\n",
            "Epoch 607/1000\n",
            "88/88 [==============================] - 0s 503us/step - loss: 0.0169\n",
            "Epoch 608/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0165\n",
            "Epoch 609/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0166\n",
            "Epoch 610/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0166\n",
            "Epoch 611/1000\n",
            "88/88 [==============================] - 0s 517us/step - loss: 0.0165\n",
            "Epoch 612/1000\n",
            "88/88 [==============================] - 0s 547us/step - loss: 0.0168\n",
            "Epoch 613/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0165\n",
            "Epoch 614/1000\n",
            "88/88 [==============================] - 0s 626us/step - loss: 0.0166\n",
            "Epoch 615/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0166\n",
            "Epoch 616/1000\n",
            "88/88 [==============================] - 0s 488us/step - loss: 0.0165\n",
            "Epoch 617/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0167\n",
            "Epoch 618/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0165\n",
            "Epoch 619/1000\n",
            "88/88 [==============================] - 0s 454us/step - loss: 0.0165\n",
            "Epoch 620/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0165\n",
            "Epoch 621/1000\n",
            "88/88 [==============================] - 0s 470us/step - loss: 0.0165\n",
            "Epoch 622/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0165\n",
            "Epoch 623/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0166\n",
            "Epoch 624/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0166\n",
            "Epoch 625/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0165\n",
            "Epoch 626/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0165\n",
            "Epoch 627/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0165\n",
            "Epoch 628/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0165\n",
            "Epoch 629/1000\n",
            "88/88 [==============================] - 0s 445us/step - loss: 0.0165\n",
            "Epoch 630/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0169\n",
            "Epoch 631/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0165\n",
            "Epoch 632/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0165\n",
            "Epoch 633/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0169\n",
            "Epoch 634/1000\n",
            "88/88 [==============================] - 0s 456us/step - loss: 0.0165\n",
            "Epoch 635/1000\n",
            "88/88 [==============================] - 0s 466us/step - loss: 0.0166\n",
            "Epoch 636/1000\n",
            "88/88 [==============================] - 0s 471us/step - loss: 0.0167\n",
            "Epoch 637/1000\n",
            "88/88 [==============================] - 0s 537us/step - loss: 0.0164\n",
            "Epoch 638/1000\n",
            "88/88 [==============================] - 0s 636us/step - loss: 0.0164\n",
            "Epoch 639/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0166\n",
            "Epoch 640/1000\n",
            "88/88 [==============================] - 0s 463us/step - loss: 0.0165\n",
            "Epoch 641/1000\n",
            "88/88 [==============================] - 0s 455us/step - loss: 0.0165\n",
            "Epoch 642/1000\n",
            "88/88 [==============================] - 0s 465us/step - loss: 0.0164\n",
            "Epoch 643/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0165\n",
            "Epoch 644/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0167\n",
            "Epoch 645/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0165\n",
            "Epoch 646/1000\n",
            "88/88 [==============================] - 0s 464us/step - loss: 0.0165\n",
            "Epoch 647/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0164\n",
            "Epoch 648/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0167\n",
            "Epoch 649/1000\n",
            "88/88 [==============================] - 0s 462us/step - loss: 0.0165\n",
            "Epoch 650/1000\n",
            "88/88 [==============================] - 0s 437us/step - loss: 0.0165\n",
            "Epoch 651/1000\n",
            "88/88 [==============================] - 0s 452us/step - loss: 0.0165\n",
            "Epoch 652/1000\n",
            "88/88 [==============================] - 0s 470us/step - loss: 0.0165\n",
            "Epoch 653/1000\n",
            "88/88 [==============================] - 0s 458us/step - loss: 0.0165\n",
            "Epoch 654/1000\n",
            "88/88 [==============================] - 0s 463us/step - loss: 0.0164\n",
            "Epoch 655/1000\n",
            "88/88 [==============================] - 0s 456us/step - loss: 0.0168\n",
            "Epoch 656/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0165\n",
            "Epoch 657/1000\n",
            "88/88 [==============================] - 0s 634us/step - loss: 0.0164\n",
            "Epoch 658/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0164\n",
            "Epoch 659/1000\n",
            "88/88 [==============================] - 0s 450us/step - loss: 0.0166\n",
            "Epoch 660/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0165\n",
            "Epoch 661/1000\n",
            "88/88 [==============================] - 0s 609us/step - loss: 0.0165\n",
            "Epoch 662/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0165\n",
            "Epoch 663/1000\n",
            "88/88 [==============================] - 0s 506us/step - loss: 0.0167\n",
            "Epoch 664/1000\n",
            "88/88 [==============================] - 0s 472us/step - loss: 0.0169\n",
            "Epoch 665/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0164\n",
            "Epoch 666/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0164\n",
            "Epoch 667/1000\n",
            "88/88 [==============================] - 0s 472us/step - loss: 0.0166\n",
            "Epoch 668/1000\n",
            "88/88 [==============================] - 0s 500us/step - loss: 0.0165\n",
            "Epoch 669/1000\n",
            "88/88 [==============================] - 0s 472us/step - loss: 0.0165\n",
            "Epoch 670/1000\n",
            "88/88 [==============================] - 0s 511us/step - loss: 0.0166\n",
            "Epoch 671/1000\n",
            "88/88 [==============================] - 0s 526us/step - loss: 0.0166\n",
            "Epoch 672/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0164\n",
            "Epoch 673/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0164\n",
            "Epoch 674/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0164\n",
            "Epoch 675/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0166\n",
            "Epoch 676/1000\n",
            "88/88 [==============================] - 0s 506us/step - loss: 0.0164\n",
            "Epoch 677/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0164\n",
            "Epoch 678/1000\n",
            "88/88 [==============================] - 0s 517us/step - loss: 0.0169\n",
            "Epoch 679/1000\n",
            "88/88 [==============================] - 0s 573us/step - loss: 0.0164\n",
            "Epoch 680/1000\n",
            "88/88 [==============================] - 0s 463us/step - loss: 0.0164\n",
            "Epoch 681/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0166\n",
            "Epoch 682/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0165\n",
            "Epoch 683/1000\n",
            "88/88 [==============================] - 0s 563us/step - loss: 0.0165\n",
            "Epoch 684/1000\n",
            "88/88 [==============================] - 0s 529us/step - loss: 0.0165\n",
            "Epoch 685/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0166\n",
            "Epoch 686/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0164\n",
            "Epoch 687/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0164\n",
            "Epoch 688/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0165\n",
            "Epoch 689/1000\n",
            "88/88 [==============================] - 0s 465us/step - loss: 0.0165\n",
            "Epoch 690/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0164\n",
            "Epoch 691/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0163\n",
            "Epoch 692/1000\n",
            "88/88 [==============================] - 0s 488us/step - loss: 0.0164\n",
            "Epoch 693/1000\n",
            "88/88 [==============================] - 0s 427us/step - loss: 0.0165\n",
            "Epoch 694/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0164\n",
            "Epoch 695/1000\n",
            "88/88 [==============================] - 0s 455us/step - loss: 0.0163\n",
            "Epoch 696/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0166\n",
            "Epoch 697/1000\n",
            "88/88 [==============================] - 0s 456us/step - loss: 0.0164\n",
            "Epoch 698/1000\n",
            "88/88 [==============================] - 0s 471us/step - loss: 0.0165\n",
            "Epoch 699/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0163\n",
            "Epoch 700/1000\n",
            "88/88 [==============================] - 0s 464us/step - loss: 0.0164\n",
            "Epoch 701/1000\n",
            "88/88 [==============================] - 0s 502us/step - loss: 0.0167\n",
            "Epoch 702/1000\n",
            "88/88 [==============================] - 0s 534us/step - loss: 0.0164\n",
            "Epoch 703/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0163\n",
            "Epoch 704/1000\n",
            "88/88 [==============================] - 0s 507us/step - loss: 0.0163\n",
            "Epoch 705/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0163\n",
            "Epoch 706/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0164\n",
            "Epoch 707/1000\n",
            "88/88 [==============================] - 0s 602us/step - loss: 0.0164\n",
            "Epoch 708/1000\n",
            "88/88 [==============================] - 0s 555us/step - loss: 0.0163\n",
            "Epoch 709/1000\n",
            "88/88 [==============================] - 0s 497us/step - loss: 0.0163\n",
            "Epoch 710/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0163\n",
            "Epoch 711/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0165\n",
            "Epoch 712/1000\n",
            "88/88 [==============================] - 0s 540us/step - loss: 0.0163\n",
            "Epoch 713/1000\n",
            "88/88 [==============================] - 0s 505us/step - loss: 0.0169\n",
            "Epoch 714/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0164\n",
            "Epoch 715/1000\n",
            "88/88 [==============================] - 0s 507us/step - loss: 0.0163\n",
            "Epoch 716/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0165\n",
            "Epoch 717/1000\n",
            "88/88 [==============================] - 0s 505us/step - loss: 0.0163\n",
            "Epoch 718/1000\n",
            "88/88 [==============================] - 0s 512us/step - loss: 0.0164\n",
            "Epoch 719/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0163\n",
            "Epoch 720/1000\n",
            "88/88 [==============================] - 0s 465us/step - loss: 0.0163\n",
            "Epoch 721/1000\n",
            "88/88 [==============================] - 0s 523us/step - loss: 0.0163\n",
            "Epoch 722/1000\n",
            "88/88 [==============================] - 0s 509us/step - loss: 0.0165\n",
            "Epoch 723/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0163\n",
            "Epoch 724/1000\n",
            "88/88 [==============================] - 0s 462us/step - loss: 0.0169\n",
            "Epoch 725/1000\n",
            "88/88 [==============================] - 0s 522us/step - loss: 0.0164\n",
            "Epoch 726/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0163\n",
            "Epoch 727/1000\n",
            "88/88 [==============================] - 0s 454us/step - loss: 0.0165\n",
            "Epoch 728/1000\n",
            "88/88 [==============================] - 0s 444us/step - loss: 0.0165\n",
            "Epoch 729/1000\n",
            "88/88 [==============================] - 0s 505us/step - loss: 0.0165\n",
            "Epoch 730/1000\n",
            "88/88 [==============================] - 0s 565us/step - loss: 0.0163\n",
            "Epoch 731/1000\n",
            "88/88 [==============================] - 0s 515us/step - loss: 0.0163\n",
            "Epoch 732/1000\n",
            "88/88 [==============================] - 0s 475us/step - loss: 0.0163\n",
            "Epoch 733/1000\n",
            "88/88 [==============================] - 0s 496us/step - loss: 0.0164\n",
            "Epoch 734/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0165\n",
            "Epoch 735/1000\n",
            "88/88 [==============================] - 0s 543us/step - loss: 0.0163\n",
            "Epoch 736/1000\n",
            "88/88 [==============================] - 0s 503us/step - loss: 0.0163\n",
            "Epoch 737/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0163\n",
            "Epoch 738/1000\n",
            "88/88 [==============================] - 0s 463us/step - loss: 0.0165\n",
            "Epoch 739/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0163\n",
            "Epoch 740/1000\n",
            "88/88 [==============================] - 0s 502us/step - loss: 0.0165\n",
            "Epoch 741/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0163\n",
            "Epoch 742/1000\n",
            "88/88 [==============================] - 0s 450us/step - loss: 0.0166\n",
            "Epoch 743/1000\n",
            "88/88 [==============================] - 0s 504us/step - loss: 0.0165\n",
            "Epoch 744/1000\n",
            "88/88 [==============================] - 0s 442us/step - loss: 0.0164\n",
            "Epoch 745/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0164\n",
            "Epoch 746/1000\n",
            "88/88 [==============================] - 0s 502us/step - loss: 0.0164\n",
            "Epoch 747/1000\n",
            "88/88 [==============================] - 0s 439us/step - loss: 0.0163\n",
            "Epoch 748/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0163\n",
            "Epoch 749/1000\n",
            "88/88 [==============================] - 0s 455us/step - loss: 0.0164\n",
            "Epoch 750/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0163\n",
            "Epoch 751/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0163\n",
            "Epoch 752/1000\n",
            "88/88 [==============================] - 0s 502us/step - loss: 0.0164\n",
            "Epoch 753/1000\n",
            "88/88 [==============================] - 0s 644us/step - loss: 0.0164\n",
            "Epoch 754/1000\n",
            "88/88 [==============================] - 0s 472us/step - loss: 0.0163\n",
            "Epoch 755/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0163\n",
            "Epoch 756/1000\n",
            "88/88 [==============================] - 0s 525us/step - loss: 0.0164\n",
            "Epoch 757/1000\n",
            "88/88 [==============================] - 0s 507us/step - loss: 0.0163\n",
            "Epoch 758/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0163\n",
            "Epoch 759/1000\n",
            "88/88 [==============================] - 0s 475us/step - loss: 0.0165\n",
            "Epoch 760/1000\n",
            "88/88 [==============================] - 0s 501us/step - loss: 0.0165\n",
            "Epoch 761/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0164\n",
            "Epoch 762/1000\n",
            "88/88 [==============================] - 0s 446us/step - loss: 0.0164\n",
            "Epoch 763/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0163\n",
            "Epoch 764/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0163\n",
            "Epoch 765/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0164\n",
            "Epoch 766/1000\n",
            "88/88 [==============================] - 0s 459us/step - loss: 0.0163\n",
            "Epoch 767/1000\n",
            "88/88 [==============================] - 0s 485us/step - loss: 0.0162\n",
            "Epoch 768/1000\n",
            "88/88 [==============================] - 0s 503us/step - loss: 0.0163\n",
            "Epoch 769/1000\n",
            "88/88 [==============================] - 0s 500us/step - loss: 0.0163\n",
            "Epoch 770/1000\n",
            "88/88 [==============================] - 0s 506us/step - loss: 0.0165\n",
            "Epoch 771/1000\n",
            "88/88 [==============================] - 0s 510us/step - loss: 0.0163\n",
            "Epoch 772/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0163\n",
            "Epoch 773/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0167\n",
            "Epoch 774/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0164\n",
            "Epoch 775/1000\n",
            "88/88 [==============================] - 0s 633us/step - loss: 0.0163\n",
            "Epoch 776/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0162\n",
            "Epoch 777/1000\n",
            "88/88 [==============================] - 0s 472us/step - loss: 0.0165\n",
            "Epoch 778/1000\n",
            "88/88 [==============================] - 0s 523us/step - loss: 0.0163\n",
            "Epoch 779/1000\n",
            "88/88 [==============================] - 0s 520us/step - loss: 0.0163\n",
            "Epoch 780/1000\n",
            "88/88 [==============================] - 0s 511us/step - loss: 0.0162\n",
            "Epoch 781/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0162\n",
            "Epoch 782/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0163\n",
            "Epoch 783/1000\n",
            "88/88 [==============================] - 0s 502us/step - loss: 0.0163\n",
            "Epoch 784/1000\n",
            "88/88 [==============================] - 0s 509us/step - loss: 0.0166\n",
            "Epoch 785/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0166\n",
            "Epoch 786/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0162\n",
            "Epoch 787/1000\n",
            "88/88 [==============================] - 0s 448us/step - loss: 0.0166\n",
            "Epoch 788/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0163\n",
            "Epoch 789/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0162\n",
            "Epoch 790/1000\n",
            "88/88 [==============================] - 0s 530us/step - loss: 0.0163\n",
            "Epoch 791/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0163\n",
            "Epoch 792/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0164\n",
            "Epoch 793/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0164\n",
            "Epoch 794/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0162\n",
            "Epoch 795/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0165\n",
            "Epoch 796/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0163\n",
            "Epoch 797/1000\n",
            "88/88 [==============================] - 0s 505us/step - loss: 0.0163\n",
            "Epoch 798/1000\n",
            "88/88 [==============================] - 0s 659us/step - loss: 0.0162\n",
            "Epoch 799/1000\n",
            "88/88 [==============================] - 0s 496us/step - loss: 0.0162\n",
            "Epoch 800/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0164\n",
            "Epoch 801/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0163\n",
            "Epoch 802/1000\n",
            "88/88 [==============================] - 0s 547us/step - loss: 0.0162\n",
            "Epoch 803/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0163\n",
            "Epoch 804/1000\n",
            "88/88 [==============================] - 0s 470us/step - loss: 0.0162\n",
            "Epoch 805/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0162\n",
            "Epoch 806/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0164\n",
            "Epoch 807/1000\n",
            "88/88 [==============================] - 0s 527us/step - loss: 0.0164\n",
            "Epoch 808/1000\n",
            "88/88 [==============================] - 0s 502us/step - loss: 0.0163\n",
            "Epoch 809/1000\n",
            "88/88 [==============================] - 0s 472us/step - loss: 0.0162\n",
            "Epoch 810/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0164\n",
            "Epoch 811/1000\n",
            "88/88 [==============================] - 0s 426us/step - loss: 0.0163\n",
            "Epoch 812/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0162\n",
            "Epoch 813/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0162\n",
            "Epoch 814/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0162\n",
            "Epoch 815/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0162\n",
            "Epoch 816/1000\n",
            "88/88 [==============================] - 0s 445us/step - loss: 0.0167\n",
            "Epoch 817/1000\n",
            "88/88 [==============================] - 0s 497us/step - loss: 0.0165\n",
            "Epoch 818/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0162\n",
            "Epoch 819/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0162\n",
            "Epoch 820/1000\n",
            "88/88 [==============================] - 0s 465us/step - loss: 0.0164\n",
            "Epoch 821/1000\n",
            "88/88 [==============================] - 0s 604us/step - loss: 0.0163\n",
            "Epoch 822/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0164\n",
            "Epoch 823/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0162\n",
            "Epoch 824/1000\n",
            "88/88 [==============================] - 0s 452us/step - loss: 0.0162\n",
            "Epoch 825/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0163\n",
            "Epoch 826/1000\n",
            "88/88 [==============================] - 0s 504us/step - loss: 0.0162\n",
            "Epoch 827/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0164\n",
            "Epoch 828/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0164\n",
            "Epoch 829/1000\n",
            "88/88 [==============================] - 0s 475us/step - loss: 0.0162\n",
            "Epoch 830/1000\n",
            "88/88 [==============================] - 0s 464us/step - loss: 0.0166\n",
            "Epoch 831/1000\n",
            "88/88 [==============================] - 0s 450us/step - loss: 0.0163\n",
            "Epoch 832/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0162\n",
            "Epoch 833/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0162\n",
            "Epoch 834/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0162\n",
            "Epoch 835/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0166\n",
            "Epoch 836/1000\n",
            "88/88 [==============================] - 0s 460us/step - loss: 0.0165\n",
            "Epoch 837/1000\n",
            "88/88 [==============================] - 0s 453us/step - loss: 0.0162\n",
            "Epoch 838/1000\n",
            "88/88 [==============================] - 0s 488us/step - loss: 0.0162\n",
            "Epoch 839/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0162\n",
            "Epoch 840/1000\n",
            "88/88 [==============================] - 0s 463us/step - loss: 0.0165\n",
            "Epoch 841/1000\n",
            "88/88 [==============================] - 0s 452us/step - loss: 0.0162\n",
            "Epoch 842/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0162\n",
            "Epoch 843/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0162\n",
            "Epoch 844/1000\n",
            "88/88 [==============================] - 0s 546us/step - loss: 0.0162\n",
            "Epoch 845/1000\n",
            "88/88 [==============================] - 0s 590us/step - loss: 0.0162\n",
            "Epoch 846/1000\n",
            "88/88 [==============================] - 0s 510us/step - loss: 0.0162\n",
            "Epoch 847/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0166\n",
            "Epoch 848/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0162\n",
            "Epoch 849/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0162\n",
            "Epoch 850/1000\n",
            "88/88 [==============================] - 0s 449us/step - loss: 0.0161\n",
            "Epoch 851/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0162\n",
            "Epoch 852/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0162\n",
            "Epoch 853/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0163\n",
            "Epoch 854/1000\n",
            "88/88 [==============================] - 0s 469us/step - loss: 0.0162\n",
            "Epoch 855/1000\n",
            "88/88 [==============================] - 0s 447us/step - loss: 0.0162\n",
            "Epoch 856/1000\n",
            "88/88 [==============================] - 0s 471us/step - loss: 0.0163\n",
            "Epoch 857/1000\n",
            "88/88 [==============================] - 0s 539us/step - loss: 0.0163\n",
            "Epoch 858/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0162\n",
            "Epoch 859/1000\n",
            "88/88 [==============================] - 0s 475us/step - loss: 0.0164\n",
            "Epoch 860/1000\n",
            "88/88 [==============================] - 0s 503us/step - loss: 0.0162\n",
            "Epoch 861/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0164\n",
            "Epoch 862/1000\n",
            "88/88 [==============================] - 0s 540us/step - loss: 0.0162\n",
            "Epoch 863/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0162\n",
            "Epoch 864/1000\n",
            "88/88 [==============================] - 0s 492us/step - loss: 0.0163\n",
            "Epoch 865/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0163\n",
            "Epoch 866/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0165\n",
            "Epoch 867/1000\n",
            "88/88 [==============================] - 0s 567us/step - loss: 0.0162\n",
            "Epoch 868/1000\n",
            "88/88 [==============================] - 0s 563us/step - loss: 0.0162\n",
            "Epoch 869/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0163\n",
            "Epoch 870/1000\n",
            "88/88 [==============================] - 0s 496us/step - loss: 0.0162\n",
            "Epoch 871/1000\n",
            "88/88 [==============================] - 0s 450us/step - loss: 0.0162\n",
            "Epoch 872/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0162\n",
            "Epoch 873/1000\n",
            "88/88 [==============================] - 0s 444us/step - loss: 0.0162\n",
            "Epoch 874/1000\n",
            "88/88 [==============================] - 0s 466us/step - loss: 0.0163\n",
            "Epoch 875/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0163\n",
            "Epoch 876/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0162\n",
            "Epoch 877/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0161\n",
            "Epoch 878/1000\n",
            "88/88 [==============================] - 0s 455us/step - loss: 0.0168\n",
            "Epoch 879/1000\n",
            "88/88 [==============================] - 0s 496us/step - loss: 0.0161\n",
            "Epoch 880/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0163\n",
            "Epoch 881/1000\n",
            "88/88 [==============================] - 0s 463us/step - loss: 0.0162\n",
            "Epoch 882/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0161\n",
            "Epoch 883/1000\n",
            "88/88 [==============================] - 0s 500us/step - loss: 0.0162\n",
            "Epoch 884/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0161\n",
            "Epoch 885/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0161\n",
            "Epoch 886/1000\n",
            "88/88 [==============================] - 0s 503us/step - loss: 0.0162\n",
            "Epoch 887/1000\n",
            "88/88 [==============================] - 0s 506us/step - loss: 0.0161\n",
            "Epoch 888/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0162\n",
            "Epoch 889/1000\n",
            "88/88 [==============================] - 0s 523us/step - loss: 0.0164\n",
            "Epoch 890/1000\n",
            "88/88 [==============================] - 0s 549us/step - loss: 0.0163\n",
            "Epoch 891/1000\n",
            "88/88 [==============================] - 0s 583us/step - loss: 0.0161\n",
            "Epoch 892/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0163\n",
            "Epoch 893/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0161\n",
            "Epoch 894/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0162\n",
            "Epoch 895/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0162\n",
            "Epoch 896/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0163\n",
            "Epoch 897/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0163\n",
            "Epoch 898/1000\n",
            "88/88 [==============================] - 0s 502us/step - loss: 0.0162\n",
            "Epoch 899/1000\n",
            "88/88 [==============================] - 0s 580us/step - loss: 0.0163\n",
            "Epoch 900/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0161\n",
            "Epoch 901/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0161\n",
            "Epoch 902/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0162\n",
            "Epoch 903/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0161\n",
            "Epoch 904/1000\n",
            "88/88 [==============================] - 0s 478us/step - loss: 0.0161\n",
            "Epoch 905/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0161\n",
            "Epoch 906/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0161\n",
            "Epoch 907/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0162\n",
            "Epoch 908/1000\n",
            "88/88 [==============================] - 0s 496us/step - loss: 0.0161\n",
            "Epoch 909/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0162\n",
            "Epoch 910/1000\n",
            "88/88 [==============================] - 0s 465us/step - loss: 0.0162\n",
            "Epoch 911/1000\n",
            "88/88 [==============================] - 0s 488us/step - loss: 0.0163\n",
            "Epoch 912/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0162\n",
            "Epoch 913/1000\n",
            "88/88 [==============================] - 0s 602us/step - loss: 0.0161\n",
            "Epoch 914/1000\n",
            "88/88 [==============================] - 0s 532us/step - loss: 0.0162\n",
            "Epoch 915/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0162\n",
            "Epoch 916/1000\n",
            "88/88 [==============================] - 0s 460us/step - loss: 0.0162\n",
            "Epoch 917/1000\n",
            "88/88 [==============================] - 0s 471us/step - loss: 0.0164\n",
            "Epoch 918/1000\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.0163\n",
            "Epoch 919/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0166\n",
            "Epoch 920/1000\n",
            "88/88 [==============================] - 0s 457us/step - loss: 0.0162\n",
            "Epoch 921/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0161\n",
            "Epoch 922/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0161\n",
            "Epoch 923/1000\n",
            "88/88 [==============================] - 0s 454us/step - loss: 0.0162\n",
            "Epoch 924/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0161\n",
            "Epoch 925/1000\n",
            "88/88 [==============================] - 0s 510us/step - loss: 0.0161\n",
            "Epoch 926/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0161\n",
            "Epoch 927/1000\n",
            "88/88 [==============================] - 0s 436us/step - loss: 0.0163\n",
            "Epoch 928/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0164\n",
            "Epoch 929/1000\n",
            "88/88 [==============================] - 0s 447us/step - loss: 0.0165\n",
            "Epoch 930/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0161\n",
            "Epoch 931/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0160\n",
            "Epoch 932/1000\n",
            "88/88 [==============================] - 0s 503us/step - loss: 0.0161\n",
            "Epoch 933/1000\n",
            "88/88 [==============================] - 0s 460us/step - loss: 0.0162\n",
            "Epoch 934/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0161\n",
            "Epoch 935/1000\n",
            "88/88 [==============================] - 0s 521us/step - loss: 0.0161\n",
            "Epoch 936/1000\n",
            "88/88 [==============================] - 0s 535us/step - loss: 0.0164\n",
            "Epoch 937/1000\n",
            "88/88 [==============================] - 0s 548us/step - loss: 0.0162\n",
            "Epoch 938/1000\n",
            "88/88 [==============================] - 0s 499us/step - loss: 0.0161\n",
            "Epoch 939/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0162\n",
            "Epoch 940/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0166\n",
            "Epoch 941/1000\n",
            "88/88 [==============================] - 0s 500us/step - loss: 0.0161\n",
            "Epoch 942/1000\n",
            "88/88 [==============================] - 0s 483us/step - loss: 0.0160\n",
            "Epoch 943/1000\n",
            "88/88 [==============================] - 0s 486us/step - loss: 0.0162\n",
            "Epoch 944/1000\n",
            "88/88 [==============================] - 0s 475us/step - loss: 0.0161\n",
            "Epoch 945/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0160\n",
            "Epoch 946/1000\n",
            "88/88 [==============================] - 0s 472us/step - loss: 0.0161\n",
            "Epoch 947/1000\n",
            "88/88 [==============================] - 0s 491us/step - loss: 0.0161\n",
            "Epoch 948/1000\n",
            "88/88 [==============================] - 0s 464us/step - loss: 0.0161\n",
            "Epoch 949/1000\n",
            "88/88 [==============================] - 0s 473us/step - loss: 0.0162\n",
            "Epoch 950/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0162\n",
            "Epoch 951/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0162\n",
            "Epoch 952/1000\n",
            "88/88 [==============================] - 0s 496us/step - loss: 0.0161\n",
            "Epoch 953/1000\n",
            "88/88 [==============================] - 0s 459us/step - loss: 0.0164\n",
            "Epoch 954/1000\n",
            "88/88 [==============================] - 0s 509us/step - loss: 0.0161\n",
            "Epoch 955/1000\n",
            "88/88 [==============================] - 0s 533us/step - loss: 0.0161\n",
            "Epoch 956/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0163\n",
            "Epoch 957/1000\n",
            "88/88 [==============================] - 0s 446us/step - loss: 0.0161\n",
            "Epoch 958/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0163\n",
            "Epoch 959/1000\n",
            "88/88 [==============================] - 0s 556us/step - loss: 0.0162\n",
            "Epoch 960/1000\n",
            "88/88 [==============================] - 0s 587us/step - loss: 0.0163\n",
            "Epoch 961/1000\n",
            "88/88 [==============================] - 0s 482us/step - loss: 0.0161\n",
            "Epoch 962/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0160\n",
            "Epoch 963/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0164\n",
            "Epoch 964/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0163\n",
            "Epoch 965/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0161\n",
            "Epoch 966/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0161\n",
            "Epoch 967/1000\n",
            "88/88 [==============================] - 0s 481us/step - loss: 0.0161\n",
            "Epoch 968/1000\n",
            "88/88 [==============================] - 0s 502us/step - loss: 0.0161\n",
            "Epoch 969/1000\n",
            "88/88 [==============================] - 0s 427us/step - loss: 0.0160\n",
            "Epoch 970/1000\n",
            "88/88 [==============================] - 0s 476us/step - loss: 0.0161\n",
            "Epoch 971/1000\n",
            "88/88 [==============================] - 0s 506us/step - loss: 0.0160\n",
            "Epoch 972/1000\n",
            "88/88 [==============================] - 0s 466us/step - loss: 0.0161\n",
            "Epoch 973/1000\n",
            "88/88 [==============================] - 0s 475us/step - loss: 0.0160\n",
            "Epoch 974/1000\n",
            "88/88 [==============================] - 0s 450us/step - loss: 0.0162\n",
            "Epoch 975/1000\n",
            "88/88 [==============================] - 0s 465us/step - loss: 0.0161\n",
            "Epoch 976/1000\n",
            "88/88 [==============================] - 0s 514us/step - loss: 0.0161\n",
            "Epoch 977/1000\n",
            "88/88 [==============================] - 0s 465us/step - loss: 0.0163\n",
            "Epoch 978/1000\n",
            "88/88 [==============================] - 0s 468us/step - loss: 0.0162\n",
            "Epoch 979/1000\n",
            "88/88 [==============================] - 0s 460us/step - loss: 0.0161\n",
            "Epoch 980/1000\n",
            "88/88 [==============================] - 0s 474us/step - loss: 0.0166\n",
            "Epoch 981/1000\n",
            "88/88 [==============================] - 0s 527us/step - loss: 0.0164\n",
            "Epoch 982/1000\n",
            "88/88 [==============================] - 0s 477us/step - loss: 0.0161\n",
            "Epoch 983/1000\n",
            "88/88 [==============================] - 0s 643us/step - loss: 0.0160\n",
            "Epoch 984/1000\n",
            "88/88 [==============================] - 0s 488us/step - loss: 0.0160\n",
            "Epoch 985/1000\n",
            "88/88 [==============================] - 0s 479us/step - loss: 0.0161\n",
            "Epoch 986/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0161\n",
            "Epoch 987/1000\n",
            "88/88 [==============================] - 0s 484us/step - loss: 0.0160\n",
            "Epoch 988/1000\n",
            "88/88 [==============================] - 0s 490us/step - loss: 0.0162\n",
            "Epoch 989/1000\n",
            "88/88 [==============================] - 0s 513us/step - loss: 0.0161\n",
            "Epoch 990/1000\n",
            "88/88 [==============================] - 0s 539us/step - loss: 0.0161\n",
            "Epoch 991/1000\n",
            "88/88 [==============================] - 0s 500us/step - loss: 0.0162\n",
            "Epoch 992/1000\n",
            "88/88 [==============================] - 0s 487us/step - loss: 0.0161\n",
            "Epoch 993/1000\n",
            "88/88 [==============================] - 0s 498us/step - loss: 0.0161\n",
            "Epoch 994/1000\n",
            "88/88 [==============================] - 0s 489us/step - loss: 0.0161\n",
            "Epoch 995/1000\n",
            "88/88 [==============================] - 0s 480us/step - loss: 0.0160\n",
            "Epoch 996/1000\n",
            "88/88 [==============================] - 0s 495us/step - loss: 0.0161\n",
            "Epoch 997/1000\n",
            "88/88 [==============================] - 0s 461us/step - loss: 0.0160\n",
            "Epoch 998/1000\n",
            "88/88 [==============================] - 0s 467us/step - loss: 0.0161\n",
            "Epoch 999/1000\n",
            "88/88 [==============================] - 0s 472us/step - loss: 0.0162\n",
            "Epoch 1000/1000\n",
            "88/88 [==============================] - 0s 493us/step - loss: 0.0162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f34d72accc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "Fa9ki9vojKI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04504f37-8393-4778-da74-04b1a2962df1"
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88, 7, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "qlaXaC63jKI9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Salva o modelo\n",
        "model.save('lstm_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hHz6YBxTjKJB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Avalia a Performance do Modelo"
      ]
    },
    {
      "metadata": {
        "id": "610ydHWpjKJC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Gerando previsões\n",
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HPvzY4T3jKJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "93be47f9-f589-445e-b260-ff56eede2cd2"
      },
      "cell_type": "code",
      "source": [
        "# Print dos erros de treino e de teste\n",
        "training_error = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Erro em Treinamento = %.3f %%' % training_error)\n",
        "\n",
        "testing_error = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Erro em Teste = %.3f %%' %  testing_error)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Erro em Treinamento = 0.016 %\n",
            "Erro em Teste = 0.014 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BQGH7re3jKJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "212ff0f8-1c7d-4e95-d8fa-16d93f649ac3"
      },
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Plot da série original\n",
        "plt.plot(dataset,color = 'k')\n",
        "\n",
        "# Plot das previsões em treino\n",
        "split_pt = train_test_split + window_size \n",
        "plt.plot(np.arange(window_size,split_pt,1),train_predict,color = 'b')\n",
        "\n",
        "# plot das previsões em treino\n",
        "plt.plot(np.arange(split_pt,split_pt + len(test_predict),1),test_predict,color = 'r')\n",
        "\n",
        "# Plot\n",
        "plt.xlabel('Dia')\n",
        "plt.ylabel('Preço das Ações da Apple')\n",
        "plt.legend(['Série Original','Previsões em Treino','Previsões em Teste'], loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAEGCAYAAAA0Z6ySAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZQdCf4HxjKJQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Previsões com Novos Conjuntos de Dados"
      ]
    },
    {
      "metadata": {
        "id": "O-VqpfsDjKJQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "No arquivo pdf onde você encontrou este Jupyter Notebook, estão descritos o procedimento para aplicar seu modelo criado a novos conjuntos de dados. Tudo que você fez no seu conjunto de dados para realizar o treinamento, deve ser repetido em um novo conjunto de dados que você queira usar para fazer as previsões. Vejamos um exemplo."
      ]
    },
    {
      "metadata": {
        "id": "Y9Cf5sz8jKJS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Carregando o modelo treinado. Repare que o nome agora é \"modelo\" e não mais \"model\". \n",
        "modelo = load_model('lstm_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "obKmrz6njKJU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Aqui está seu novo conjunto de dados. \n",
        "# Na verdade pegamos os últimos registros do dataset e queremos prever o próximo item da série.\n",
        "# Perceba que os dados já estão padronizados, pois foi assim que treinamos nosso modelo.\n",
        "new_data = [-4.362395529396456695e-02,\n",
        "            2.155369823552977238e-02,\n",
        "            2.647844739615612397e-02,\n",
        "            -4.167795105803762112e-02,\n",
        "            -7.888723449334911209e-02,\n",
        "            -5.797255139894330611e-02,\n",
        "            2.305824869067012450e-01,\n",
        "            3.360086521611651555e-01]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LtTtQ7TNjKJW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "daa3f2ec-bd68-4486-eff4-eaafac1ba52a"
      },
      "cell_type": "code",
      "source": [
        "# Visualizando os novos dados\n",
        "new_data"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.04362395529396457,\n",
              " 0.021553698235529772,\n",
              " 0.026478447396156124,\n",
              " -0.04167795105803762,\n",
              " -0.07888723449334911,\n",
              " -0.057972551398943306,\n",
              " 0.23058248690670125,\n",
              " 0.33600865216116516]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "kKG-pjcPjKJa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Agora aplicamos aos novos dados as mesms transformações aplicadas antes do processo de treinamento.\n",
        "# Criaremos o objeto new_X para diferenciar do objeto X usado no treinamento\n",
        "window_size = 7\n",
        "series = new_data\n",
        "new_X = np.asarray([series[i:(i + window_size)] for i in range(len(series) - window_size)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YZlGofLvjKJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a08a0040-10dc-4bfd-9158-95aef3f91376"
      },
      "cell_type": "code",
      "source": [
        "# Shape de new_X (compare com o shape de X no início deste notebook)\n",
        "new_X.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "YRfQ_Y4ajKJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c01c8dbc-f210-477d-9f95-1ded15da0bb4"
      },
      "cell_type": "code",
      "source": [
        "print(new_X)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.04362396  0.0215537   0.02647845 -0.04167795 -0.07888723 -0.05797255\n",
            "   0.23058249]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q29Esr91jKJm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# O modelo LSTM espera receber os dados com 3 dimensões e por isso precisamos fazer o reshape.\n",
        "# Fizemos o mesmo durante o pré-processamento dos dados antes de criar o modelo.\n",
        "final_X = np.asarray(np.reshape(new_X, (new_X.shape[0], window_size, 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LaSboe_njKJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ebc09ad-ed9f-412e-d4c4-3e55bc21a82c"
      },
      "cell_type": "code",
      "source": [
        "# Shape\n",
        "final_X.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 7, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "1lylM9Rcl36E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "51a58937-924f-4814-c341-b6a670797b4c"
      },
      "cell_type": "code",
      "source": [
        "final_X"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.04362396],\n",
              "        [ 0.0215537 ],\n",
              "        [ 0.02647845],\n",
              "        [-0.04167795],\n",
              "        [-0.07888723],\n",
              "        [-0.05797255],\n",
              "        [ 0.23058249]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "1tkpw9TijKJs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Agora fazemos as previsões com nosso modelo usando o novo conjunto de dados\n",
        "pred = modelo.predict(final_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rhfNYVFhjKJv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "135a7f5a-244c-4388-be1f-253b3dd445b9"
      },
      "cell_type": "code",
      "source": [
        "print(\"Próximo valor na série: \", pred)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Próximo valor na série:  [[0.21817902]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9aXrnBfujKJy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fim"
      ]
    }
  ]
}